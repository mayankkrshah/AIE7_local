{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJXW_DgiSebM"
      },
      "source": [
        "# LangGraph and LangSmith - Agentic RAG Powered by LangChain\n",
        "\n",
        "In the following notebook we'll complete the following tasks:\n",
        "\n",
        "- ü§ù Breakout Room #1:\n",
        "  1. Install required libraries\n",
        "  2. Set Environment Variables\n",
        "  3. Creating our Tool Belt\n",
        "  4. Creating Our State\n",
        "  5. Creating and Compiling A Graph!\n",
        "\n",
        "- ü§ù Breakout Room #2:\n",
        "  1. Evaluating the LangGraph Application with LangSmith\n",
        "  2. Adding Helpfulness Check and \"Loop\" Limits\n",
        "  3. LangGraph for the \"Patterns\" of GenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djQ3nRAgoF67"
      },
      "source": [
        "# ü§ù Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7pQDUhUnIo8"
      },
      "source": [
        "## Part 1: LangGraph - Building Cyclic Applications with LangChain\n",
        "\n",
        "LangGraph is a tool that leverages LangChain Expression Language to build coordinated multi-actor and stateful applications that includes cyclic behaviour.\n",
        "\n",
        "### Why Cycles?\n",
        "\n",
        "In essence, we can think of a cycle in our graph as a more robust and customizable loop. It allows us to keep our application agent-forward while still giving the powerful functionality of traditional loops.\n",
        "\n",
        "Due to the inclusion of cycles over loops, we can also compose rather complex flows through our graph in a much more readable and natural fashion. Effectively allowing us to recreate application flowcharts in code in an almost 1-to-1 fashion.\n",
        "\n",
        "### Why LangGraph?\n",
        "\n",
        "Beyond the agent-forward approach - we can easily compose and combine traditional \"DAG\" (directed acyclic graph) chains with powerful cyclic behaviour due to the tight integration with LCEL. This means it's a natural extension to LangChain's core offerings!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_fLDElOVoop"
      },
      "source": [
        "## Task 1:  Dependencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wujPjGJuoPwg"
      },
      "source": [
        "## Task 2: Environment Variables\n",
        "\n",
        "We'll want to set both our OpenAI API key and our LangSmith environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdh8CoVWHRvs",
        "outputId": "3fa78560-393c-4ee5-b871-9886bf0d70f4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# import getpass\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
        "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkla2fpx28QK",
        "outputId": "52d7ad22-fcb1-4abe-853b-216c55a12650"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv0glIDyHmRt",
        "outputId": "b69df90a-b4e1-4ddb-9de0-882d98b68ab2"
      },
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE7 - LangGraph - {uuid4().hex[0:8]}\"\n",
        "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBRyQmEAVzua"
      },
      "source": [
        "## Task 3: Creating our Tool Belt\n",
        "\n",
        "As is usually the case, we'll want to equip our agent with a toolbelt to help answer questions and add external knowledge.\n",
        "\n",
        "There's a tonne of tools in the [LangChain Community Repo](https://github.com/langchain-ai/langchain-community/tree/main/libs/community) but we'll stick to a couple just so we can observe the cyclic nature of LangGraph in action!\n",
        "\n",
        "We'll leverage:\n",
        "\n",
        "- [Tavily Search Results](https://github.com/langchain-ai/langchain-community/blob/main/libs/community/langchain_community/tools/tavily_search/tool.py)\n",
        "- [Arxiv](https://github.com/langchain-ai/langchain-community/blob/main/libs/community/langchain_community/tools/arxiv/tool.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k6n_Dob2F46"
      },
      "source": [
        "#### üèóÔ∏è Activity #1:\n",
        "\n",
        "Please add the tools to use into our toolbelt.\n",
        "\n",
        "> NOTE: Each tool in our toolbelt should be a method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "lAxaSvlfIeOg"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
        "\n",
        "# Added 1 new tool\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "wiki_tool = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "\n",
        "tool_belt = [\n",
        "    tavily_tool,\n",
        "    ArxivQueryRun(),\n",
        "    wiki_tool\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI-C669ZYVI5"
      },
      "source": [
        "### Model\n",
        "\n",
        "Now we can set-up our model! We'll leverage the familiar OpenAI model suite for this example - but it's not *necessary* to use with LangGraph. LangGraph supports all models - though you might not find success with smaller models - as such, they recommend you stick with:\n",
        "\n",
        "- OpenAI's GPT-3.5 and GPT-4\n",
        "- Anthropic's Claude\n",
        "- Google's Gemini\n",
        "\n",
        "> NOTE: Because we're leveraging the OpenAI function calling API - we'll need to use OpenAI *for this specific example* (or any other service that exposes an OpenAI-style function calling API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "QkNS8rNZJs4z"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugkj3GzuZpQv"
      },
      "source": [
        "Now that we have our model set-up, let's \"put on the tool belt\", which is to say: We'll bind our LangChain formatted tools to the model in an OpenAI function calling format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "4OdMqFafZ_0V"
      },
      "outputs": [],
      "source": [
        "model = model.bind_tools(tool_belt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERzuGo6W18Lr"
      },
      "source": [
        "#### ‚ùì Question #1:\n",
        "How does the model determine which tool to use?\n",
        "\n",
        "Answer:\n",
        "\n",
        "The model determines which tool to use through OpenAI's function calling mechanism combined with tool descriptions and the current context. Here's how it works:\n",
        "\n",
        "1. Model reads the question\n",
        "2. Looks at available tool descriptions\n",
        "3. Picks the tool that best matches what we are asking for\n",
        "4. If no tool fits, just answers normally\n",
        "\n",
        "Basically model just picks the right tool based on user query!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_296Ub96Z_H8"
      },
      "source": [
        "## Task 4: Putting the State in Stateful\n",
        "\n",
        "Earlier we used this phrasing:\n",
        "\n",
        "`coordinated multi-actor and stateful applications`\n",
        "\n",
        "So what does that \"stateful\" mean?\n",
        "\n",
        "To put it simply - we want to have some kind of object which we can pass around our application that holds information about what the current situation (state) is. Since our system will be constructed of many parts moving in a coordinated fashion - we want to be able to ensure we have some commonly understood idea of that state.\n",
        "\n",
        "LangGraph leverages a `StatefulGraph` which uses an `AgentState` object to pass information between the various nodes of the graph.\n",
        "\n",
        "There are more options than what we'll see below - but this `AgentState` object is one that is stored in a `TypedDict` with the key `messages` and the value is a `Sequence` of `BaseMessages` that will be appended to whenever the state changes.\n",
        "\n",
        "Let's think about a simple example to help understand exactly what this means (we'll simplify a great deal to try and clearly communicate what state is doing):\n",
        "\n",
        "1. We initialize our state object:\n",
        "  - `{\"messages\" : []}`\n",
        "2. Our user submits a query to our application.\n",
        "  - New State: `HumanMessage(#1)`\n",
        "  - `{\"messages\" : [HumanMessage(#1)}`\n",
        "3. We pass our state object to an Agent node which is able to read the current state. It will use the last `HumanMessage` as input. It gets some kind of output which it will add to the state.\n",
        "  - New State: `AgentMessage(#1, additional_kwargs {\"function_call\" : \"WebSearchTool\"})`\n",
        "  - `{\"messages\" : [HumanMessage(#1), AgentMessage(#1, ...)]}`\n",
        "4. We pass our state object to a \"conditional node\" (more on this later) which reads the last state to determine if we need to use a tool - which it can determine properly because of our provided object!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "mxL9b_NZKUdL"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWsMhfO9grLu"
      },
      "source": [
        "## Task 5: It's Graphing Time!\n",
        "\n",
        "Now that we have state, and we have tools, and we have an LLM - we can finally start making our graph!\n",
        "\n",
        "Let's take a second to refresh ourselves about what a graph is in this context.\n",
        "\n",
        "Graphs, also called networks in some circles, are a collection of connected objects.\n",
        "\n",
        "The objects in question are typically called nodes, or vertices, and the connections are called edges.\n",
        "\n",
        "Let's look at a simple graph.\n",
        "\n",
        "![image](https://i.imgur.com/2NFLnIc.png)\n",
        "\n",
        "Here, we're using the coloured circles to represent the nodes and the yellow lines to represent the edges. In this case, we're looking at a fully connected graph - where each node is connected by an edge to each other node.\n",
        "\n",
        "If we were to think about nodes in the context of LangGraph - we would think of a function, or an LCEL runnable.\n",
        "\n",
        "If we were to think about edges in the context of LangGraph - we might think of them as \"paths to take\" or \"where to pass our state object next\".\n",
        "\n",
        "Let's create some nodes and expand on our diagram.\n",
        "\n",
        "> NOTE: Due to the tight integration with LCEL - we can comfortably create our nodes in an async fashion!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "91flJWtZLUrl"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "def call_model(state):\n",
        "  messages = state[\"messages\"]\n",
        "  response = model.invoke(messages)\n",
        "  return {\"messages\" : [response]}\n",
        "\n",
        "tool_node = ToolNode(tool_belt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bwR7MgWj3Wg"
      },
      "source": [
        "Now we have two total nodes. We have:\n",
        "\n",
        "- `call_model` is a node that will...well...call the model\n",
        "- `tool_node` is a node which can call a tool\n",
        "\n",
        "Let's start adding nodes! We'll update our diagram along the way to keep track of what this looks like!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vF4_lgtmQNo",
        "outputId": "a4384377-8f7a-415f-be1b-fee6169cb101"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11c410830>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "uncompiled_graph = StateGraph(AgentState)\n",
        "\n",
        "uncompiled_graph.add_node(\"agent\", call_model)\n",
        "uncompiled_graph.add_node(\"action\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8CjRlbVmRpW"
      },
      "source": [
        "Let's look at what we have so far:\n",
        "\n",
        "![image](https://i.imgur.com/md7inqG.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaXHpPeSnOWC"
      },
      "source": [
        "Next, we'll add our entrypoint. All our entrypoint does is indicate which node is called first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGCbaYqRnmiw",
        "outputId": "5351807c-2ac7-4316-a3a3-878abeacd114"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11c410830>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uncompiled_graph.set_entry_point(\"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUsfGoSpoF9U"
      },
      "source": [
        "![image](https://i.imgur.com/wNixpJe.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q_pQgHmoW0M"
      },
      "source": [
        "Now we want to build a \"conditional edge\" which will use the output state of a node to determine which path to follow.\n",
        "\n",
        "We can help conceptualize this by thinking of our conditional edge as a conditional in a flowchart!\n",
        "\n",
        "Notice how our function simply checks if there is a \"function_call\" kwarg present.\n",
        "\n",
        "Then we create an edge where the origin node is our agent node and our destination node is *either* the action node or the END (finish the graph).\n",
        "\n",
        "It's important to highlight that the dictionary passed in as the third parameter (the mapping) should be created with the possible outputs of our conditional function in mind. In this case `should_continue` outputs either `\"end\"` or `\"continue\"` which are subsequently mapped to the action node or the END node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BZgb81VQf9o",
        "outputId": "73a07c15-5f0b-40f2-b033-38b57d056dd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11c410830>"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def should_continue(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  if last_message.tool_calls:\n",
        "    return \"action\"\n",
        "\n",
        "  return END\n",
        "\n",
        "uncompiled_graph.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cvhcf4jp0Ce"
      },
      "source": [
        "Let's visualize what this looks like.\n",
        "\n",
        "![image](https://i.imgur.com/8ZNwKI5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKCjWJCkrJb9"
      },
      "source": [
        "Finally, we can add our last edge which will connect our action node to our agent node. This is because we *always* want our action node (which is used to call our tools) to return its output to our agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvcgbHf1rIXZ",
        "outputId": "45d4bdd6-d6bb-4a1d-bb79-cad43c130bf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11c410830>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uncompiled_graph.add_edge(\"action\", \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiWDwBQtrw7Z"
      },
      "source": [
        "Let's look at the final visualization.\n",
        "\n",
        "![image](https://i.imgur.com/NWO7usO.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYqDpErlsCsu"
      },
      "source": [
        "All that's left to do now is to compile our workflow - and we're off!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "zt9-KS8DpzNx"
      },
      "outputs": [],
      "source": [
        "simple_agent_graph = uncompiled_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhNWIwBL1W4Q"
      },
      "source": [
        "#### ‚ùì Question #2:\n",
        "\n",
        "Is there any specific limit to how many times we can cycle?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Yes, LangGraph enforces a default recursion limit of 25. That means an agent can cycle between nodes‚Äîlike \"agent\" and \"action\"‚Äîup to 25 times before the graph halts automatically. This built-in safeguard helps prevent infinite loops, runaway API calls, and excessive costs.\n",
        "\n",
        "\n",
        "The standard way to impose a limit is by using the recursion_limit parameter when compiling the graph. For example:\n",
        "\n",
        "```python\n",
        "graph = uncompiled_graph.compile(recursion_limit=5)\n",
        "```\n",
        "\n",
        "This sets a hard cap‚Äîonce the agent hits 5 recursive steps, the graph will stop automatically. It‚Äôs the recommended and built-in way to prevent runaway loops.\n",
        "\n",
        "Apart from that, we can also add custom limits inside our node logic. One common method is checking how many messages have been exchanged:\n",
        "\n",
        "```python\n",
        "if len(state[\"messages\"]) > 10:\n",
        "    return END\n",
        "```\n",
        "\n",
        "This is helpful in chat scenarios where we want to stop after a certain number of back-and-forths.\n",
        "Another way is to look at the content of the message and stop based on a condition:\n",
        "\n",
        "```python\n",
        "if \"STOP\" in state[\"latest_message\"][\"content\"]:\n",
        "    return END\n",
        "```\n",
        "\n",
        "This gives more flexibility and lets the agent exit based on dynamic inputs.\n",
        "\n",
        "In short, LangGraph doesn‚Äôt enforce a limit by default, but recursion_limit is the standard way to do it, and we can always layer on additional logic if needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEYcTShCsPaa"
      },
      "source": [
        "## Using Our Graph\n",
        "\n",
        "Now that we've created and compiled our graph - we can call it *just as we'd call any other* `Runnable`!\n",
        "\n",
        "Let's try out a few examples to see how it fairs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn4n37PQRPII",
        "outputId": "5eeedfae-089d-496e-e71f-071939fa5832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_UL1xsPHJpK2KCGG9btVqmcy1', 'function': {'arguments': '{\"query\":\"current captain of the Winnipeg Jets 2023\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 220, 'total_tokens': 246, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BtLiYc66mpMF6hNqfjckluLglbNFB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0b3aa6f1-cb04-4abc-a249-bf551dbb5fd7-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current captain of the Winnipeg Jets 2023'}, 'id': 'call_UL1xsPHJpK2KCGG9btVqmcy1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 220, 'output_tokens': 26, 'total_tokens': 246, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='[{\"title\": \"Adam Lowry - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/Adam_Lowry\", \"content\": \"| Awards and achievements | | |\\\\n| --- | --- | --- |\\\\n| Preceded by Stefan Elliott | Winner of the Daryl K. (Doc) Seaman Trophy_Seaman_Trophy \\\\\"Daryl K. (Doc) Seaman Trophy\\\\\")  2010 | Succeeded by Colin Smith \\\\\"Colin Smith (ice hockey)\\\\\") |\\\\n| Sporting positions | | |\\\\n| Preceded by Blake Wheeler | Winnipeg Jets captain  2023‚Äìpresent | Incumbent | [...] Entering the 2023‚Äì24 season, Lowry was named captain of the Jets on September 12, 2023. He became the third in the team\\'s history since relocating to Winnipeg, and the tenth overall in franchise history.\\\\n\\\\nOn May 4, 2025, Lowry scored at 16:10 in double overtime to win 4-3 against the St. Louis Blues in Game 7 of the Jets-Blues first round playoff series.\\\\n\\\\n## Personal life [...] Adam Lowry (born March 29, 1993) is an American-born Canadian professional ice hockey centre \\\\\"Center (ice hockey)\\\\\") and  captain \\\\\"Captain (ice hockey)\\\\\") of the Winnipeg Jets of the National Hockey League (NHL).\\\\n\\\\n## Early life\", \"score\": 0.8896154}, {\"title\": \"Adam Lowry named Jets captain | Winnipeg Jets - NHL.com\", \"url\": \"https://www.nhl.com/jets/news/adam-lowry-named-jets-captain\", \"content\": \"The 30-year-old wore an √¢\\x80\\x9cA√¢\\x80\\x9d for the first time in 2022-23 along with Josh Morrissey and Mark Scheifele who will both serve as alternates for the team this year. The Jets didn√¢\\x80\\x99t have a captain last season as head coach Rick Bowness and his staff wanted more voices in the dressing room.\\\\n\\\\n√¢\\x80\\x9cIt went well last year. Mark, Adam and Josh did a great job in the room which is what we wanted. We all know Adam is the first guy on the ice to stick up for his teammates,√¢\\x80\\x9d said Bowness. [...] √¢\\x80\\x9cHe√¢\\x80\\x99s a true professional, he has total respect from every player on the team, every player around the league and certainly from the coaching staff as well. We just feel at this point it√¢\\x80\\x99s the right time to name Adam as our captain.√¢\\x80\\x9d [...] √¢\\x80\\x9cGetting to be a captain of a Canadian NHL team is pretty special and something I√¢\\x80\\x99m really looking forward too.√¢\\x80\\x9d\", \"score\": 0.85509074}, {\"title\": \"Winnipeg Jets - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/Winnipeg_Jets\", \"content\": \"In the 2021‚Äì22 season, the Jets finished a disappointing sixth in the Central Division, missing the playoffs. At the start of the 2022‚Äì23 season, forward Blake Wheeler was stripped of the team captaincy. The Jets then clinched the 2023 playoffs at the end of the regular season, but were defeated by the eventual Stanley Cup champion Vegas Golden Knights in five games in the first round. Before the start of the 2023‚Äì24 season, forward Adam Lowry was appointed team captain. The Jets then clinched [...] | 6 | Canada | Colin Miller \\\\\"Colin Miller (ice hockey, born 1992)\\\\\") | D | R | 32 | 2024 | Sault Ste. Marie, Ontario |\\\\n| 44 | Canada | Josh Morrissey (A#Alternate_captains \\\\\"Captain (ice hockey)\\\\\")) | D | L | 30 | 2013 | Calgary, Alberta |\\\\n| 7 | Russia | Vladislav Namestnikov | C \\\\\"Centre (ice hockey)\\\\\") | L | 32 | 2023 | Voskresensk, Russia |\\\\n| 62 | Switzerland | Nino Niederreiter | RW \\\\\"Winger (ice hockey)\\\\\") | L | 32 | 2023 | Chur, Switzerland | [...] |  v  t  e  Winnipeg Jets | |\\\\n| --- | --- |\\\\n|  Formerly the Atlanta Thrashers  Founded in 1999  Based in Winnipeg, Manitoba | |\\\\n| Franchise |  Team  General managers  Coaches  Players  Captains  Draft picks   + expansion draft  Seasons  Current season |\\\\n| History |  Records  Award winners  Broadcasters |\\\\n| Personnel | Owner(s)  True North Sports & Entertainment (Mark Chipman, chairman)  General manager  Kevin Cheveldayoff  Head coach  Scott Arniel  Team captain  Adam Lowry  Current roster |\", \"score\": 0.84027237}, {\"title\": \"Team Captains of Winnipeg Jets - Elite Prospects\", \"url\": \"https://www.eliteprospects.com/team/9966/winnipeg-jets/captaincy-history\", \"content\": \"| Season | League | ‚ÄúC‚Äù Captain(s) | ‚ÄúA‚Äù Alternate Captain(s) |\\\\n| --- | --- | --- | --- |\\\\n| 2025-2026  2025-26 | NHL | Adam Lowry |  |\\\\n| 2024-2025  2024-25 | NHL | Adam Lowry | Josh Morrissey  Neal Pionk  Mark Scheifele |\\\\n| 2023-2024  2023-24 | NHL | Adam Lowry | Josh Morrissey  Mark Scheifele |\\\\n| 2022-2023  2022-23 | NHL |  | Adam Lowry  Josh Morrissey  Mark Scheifele |\\\\n| 2021-2022  2021-22 | NHL | Blake Wheeler | Josh Morrissey  Mark Scheifele | [...] | Name | League |\\\\n| --- | --- |\\\\n| Canada Andy Andreoff (F) | NL |\\\\n| USA Anthony Greco (F) | NL |\\\\n| Canada Chase Stillman (F) | AHL |\\\\n| Canada Macoy Erkamps (D) | HockeyAllsvenskan |\\\\n| USA Kieffer Bellows (F) | SHL |\\\\n| Denmark Markus Lauridsen (D) | ICEHL |\\\\n| Canada Peter Aubry (G) | Ligue Magnus |\\\\n| Sweden Victor Eklund (F) | SHL |\\\\n| Latvia Arturs Silovs (G) | NHL |\\\\n| Canada Jakin Smallwood (F) | USports |\\\\n| Canada Gavin McKenna (F) | NCAA |\\\\n| Canada Charles Martin (D) | AHL | [...] Canada\\\\nUSA\\\\nCanada\\\\nCanada\\\\nUSA\\\\nDenmark\\\\nCanada\\\\nSweden\\\\nLatvia\\\\nCanada\\\\nCanada\\\\nCanada\\\\nUSA\\\\nSlovakia\\\\nCanada\\\\nCanada\\\\nCanada\\\\nCanada\\\\nSweden\\\\nCanada\\\\n\\\\n##### Scoring Leaders\\\\n\\\\n| # | Player | GP | G | A | TP |\\\\n| --- | --- | --- | --- | --- | --- |\\\\n| 1. | Tanner Hopps | 18 | 20 | 32 | 52 |\\\\n| 2. | Yu Hikosaka | 20 | 26 | 23 | 49 |\\\\n| 3. | Scott Timmins | 18 | 16 | 31 | 47 |\\\\n| 4. | Joakim Erdugan | 21 | 13 | 33 | 46 |\\\\n| 5. | Kolton Shindle | 18 | 25 | 20 | 45 |\\\\n\\\\n##### Popular League Pages\\\\n\\\\n##### NHL Rosters\", \"score\": 0.7803451}, {\"title\": \"Lowry named Jets captain, replaces Wheeler | NHL.com\", \"url\": \"https://www.nhl.com/news/adam-lowry-named-winnipeg-captain\", \"content\": \"Lowry replaces Blake Wheeler, who was removed as captain Sept. 16, 2022, and signed with the New York Rangers after having his contract bought out this offseason. The Jets opted for three alternate captains last season; Lowry, forward Mark Scheifele and defenseman Josh Morrissey. Coach Rick Bowness said Scheifele and Morrissey will remain alternate captains. [...] NHL logo\\\\nNHL logo\\\\n\\\\n# Lowry named Jets captain, replaces Wheeler\\\\n\\\\n30-year-old forward entering 10th season with Winnipeg\\\\n\\\\nLowry_Jets\\\\n\\\\nAdam Lowry was named captain of the Winnipeg Jets on Tuesday.\\\\n\\\\nThe 30-year-old forward was selected by the Jets in the third round (No. 67) of the 2011 NHL Draft and has played his entire nine-season NHL career with Winnipeg. [...] \\'OK, Adam\\'s our captain.\\' That wasn\\'t the case at all. We had a lot of conversations over the summer with the staff, with management and everyone involved. So, ultimately we came to this conclusion.\\\\\"\", \"score\": 0.6783488}]', name='tavily_search_results_json', id='aac89da3-f9da-40ca-b494-a0e69b12ddcf', tool_call_id='call_UL1xsPHJpK2KCGG9btVqmcy1', artifact={'query': 'current captain of the Winnipeg Jets 2023', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://en.wikipedia.org/wiki/Adam_Lowry', 'title': 'Adam Lowry - Wikipedia', 'content': '| Awards and achievements | | |\\n| --- | --- | --- |\\n| Preceded by Stefan Elliott | Winner of the Daryl K. (Doc) Seaman Trophy_Seaman_Trophy \"Daryl K. (Doc) Seaman Trophy\")  2010 | Succeeded by Colin Smith \"Colin Smith (ice hockey)\") |\\n| Sporting positions | | |\\n| Preceded by Blake Wheeler | Winnipeg Jets captain  2023‚Äìpresent | Incumbent | [...] Entering the 2023‚Äì24 season, Lowry was named captain of the Jets on September 12, 2023. He became the third in the team\\'s history since relocating to Winnipeg, and the tenth overall in franchise history.\\n\\nOn May 4, 2025, Lowry scored at 16:10 in double overtime to win 4-3 against the St. Louis Blues in Game 7 of the Jets-Blues first round playoff series.\\n\\n## Personal life [...] Adam Lowry (born March 29, 1993) is an American-born Canadian professional ice hockey centre \"Center (ice hockey)\") and  captain \"Captain (ice hockey)\") of the Winnipeg Jets of the National Hockey League (NHL).\\n\\n## Early life', 'score': 0.8896154, 'raw_content': None}, {'url': 'https://www.nhl.com/jets/news/adam-lowry-named-jets-captain', 'title': 'Adam Lowry named Jets captain | Winnipeg Jets - NHL.com', 'content': 'The 30-year-old wore an √¢\\x80\\x9cA√¢\\x80\\x9d for the first time in 2022-23 along with Josh Morrissey and Mark Scheifele who will both serve as alternates for the team this year. The Jets didn√¢\\x80\\x99t have a captain last season as head coach Rick Bowness and his staff wanted more voices in the dressing room.\\n\\n√¢\\x80\\x9cIt went well last year. Mark, Adam and Josh did a great job in the room which is what we wanted. We all know Adam is the first guy on the ice to stick up for his teammates,√¢\\x80\\x9d said Bowness. [...] √¢\\x80\\x9cHe√¢\\x80\\x99s a true professional, he has total respect from every player on the team, every player around the league and certainly from the coaching staff as well. We just feel at this point it√¢\\x80\\x99s the right time to name Adam as our captain.√¢\\x80\\x9d [...] √¢\\x80\\x9cGetting to be a captain of a Canadian NHL team is pretty special and something I√¢\\x80\\x99m really looking forward too.√¢\\x80\\x9d', 'score': 0.85509074, 'raw_content': None}, {'url': 'https://en.wikipedia.org/wiki/Winnipeg_Jets', 'title': 'Winnipeg Jets - Wikipedia', 'content': 'In the 2021‚Äì22 season, the Jets finished a disappointing sixth in the Central Division, missing the playoffs. At the start of the 2022‚Äì23 season, forward Blake Wheeler was stripped of the team captaincy. The Jets then clinched the 2023 playoffs at the end of the regular season, but were defeated by the eventual Stanley Cup champion Vegas Golden Knights in five games in the first round. Before the start of the 2023‚Äì24 season, forward Adam Lowry was appointed team captain. The Jets then clinched [...] | 6 | Canada | Colin Miller \"Colin Miller (ice hockey, born 1992)\") | D | R | 32 | 2024 | Sault Ste. Marie, Ontario |\\n| 44 | Canada | Josh Morrissey (A#Alternate_captains \"Captain (ice hockey)\")) | D | L | 30 | 2013 | Calgary, Alberta |\\n| 7 | Russia | Vladislav Namestnikov | C \"Centre (ice hockey)\") | L | 32 | 2023 | Voskresensk, Russia |\\n| 62 | Switzerland | Nino Niederreiter | RW \"Winger (ice hockey)\") | L | 32 | 2023 | Chur, Switzerland | [...] |  v  t  e  Winnipeg Jets | |\\n| --- | --- |\\n|  Formerly the Atlanta Thrashers  Founded in 1999  Based in Winnipeg, Manitoba | |\\n| Franchise |  Team  General managers  Coaches  Players  Captains  Draft picks   + expansion draft  Seasons  Current season |\\n| History |  Records  Award winners  Broadcasters |\\n| Personnel | Owner(s)  True North Sports & Entertainment (Mark Chipman, chairman)  General manager  Kevin Cheveldayoff  Head coach  Scott Arniel  Team captain  Adam Lowry  Current roster |', 'score': 0.84027237, 'raw_content': None}, {'url': 'https://www.eliteprospects.com/team/9966/winnipeg-jets/captaincy-history', 'title': 'Team Captains of Winnipeg Jets - Elite Prospects', 'content': '| Season | League | ‚ÄúC‚Äù Captain(s) | ‚ÄúA‚Äù Alternate Captain(s) |\\n| --- | --- | --- | --- |\\n| 2025-2026  2025-26 | NHL | Adam Lowry |  |\\n| 2024-2025  2024-25 | NHL | Adam Lowry | Josh Morrissey  Neal Pionk  Mark Scheifele |\\n| 2023-2024  2023-24 | NHL | Adam Lowry | Josh Morrissey  Mark Scheifele |\\n| 2022-2023  2022-23 | NHL |  | Adam Lowry  Josh Morrissey  Mark Scheifele |\\n| 2021-2022  2021-22 | NHL | Blake Wheeler | Josh Morrissey  Mark Scheifele | [...] | Name | League |\\n| --- | --- |\\n| Canada Andy Andreoff (F) | NL |\\n| USA Anthony Greco (F) | NL |\\n| Canada Chase Stillman (F) | AHL |\\n| Canada Macoy Erkamps (D) | HockeyAllsvenskan |\\n| USA Kieffer Bellows (F) | SHL |\\n| Denmark Markus Lauridsen (D) | ICEHL |\\n| Canada Peter Aubry (G) | Ligue Magnus |\\n| Sweden Victor Eklund (F) | SHL |\\n| Latvia Arturs Silovs (G) | NHL |\\n| Canada Jakin Smallwood (F) | USports |\\n| Canada Gavin McKenna (F) | NCAA |\\n| Canada Charles Martin (D) | AHL | [...] Canada\\nUSA\\nCanada\\nCanada\\nUSA\\nDenmark\\nCanada\\nSweden\\nLatvia\\nCanada\\nCanada\\nCanada\\nUSA\\nSlovakia\\nCanada\\nCanada\\nCanada\\nCanada\\nSweden\\nCanada\\n\\n##### Scoring Leaders\\n\\n| # | Player | GP | G | A | TP |\\n| --- | --- | --- | --- | --- | --- |\\n| 1. | Tanner Hopps | 18 | 20 | 32 | 52 |\\n| 2. | Yu Hikosaka | 20 | 26 | 23 | 49 |\\n| 3. | Scott Timmins | 18 | 16 | 31 | 47 |\\n| 4. | Joakim Erdugan | 21 | 13 | 33 | 46 |\\n| 5. | Kolton Shindle | 18 | 25 | 20 | 45 |\\n\\n##### Popular League Pages\\n\\n##### NHL Rosters', 'score': 0.7803451, 'raw_content': None}, {'url': 'https://www.nhl.com/news/adam-lowry-named-winnipeg-captain', 'title': 'Lowry named Jets captain, replaces Wheeler | NHL.com', 'content': 'Lowry replaces Blake Wheeler, who was removed as captain Sept. 16, 2022, and signed with the New York Rangers after having his contract bought out this offseason. The Jets opted for three alternate captains last season; Lowry, forward Mark Scheifele and defenseman Josh Morrissey. Coach Rick Bowness said Scheifele and Morrissey will remain alternate captains. [...] NHL logo\\nNHL logo\\n\\n# Lowry named Jets captain, replaces Wheeler\\n\\n30-year-old forward entering 10th season with Winnipeg\\n\\nLowry_Jets\\n\\nAdam Lowry was named captain of the Winnipeg Jets on Tuesday.\\n\\nThe 30-year-old forward was selected by the Jets in the third round (No. 67) of the 2011 NHL Draft and has played his entire nine-season NHL career with Winnipeg. [...] \\'OK, Adam\\'s our captain.\\' That wasn\\'t the case at all. We had a lot of conversations over the summer with the staff, with management and everyone involved. So, ultimately we came to this conclusion.\"', 'score': 0.6783488, 'raw_content': None}], 'response_time': 3.78})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='The current captain of the Winnipeg Jets is Adam Lowry. He was named captain on September 12, 2023.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 2195, 'total_tokens': 2221, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BtLiduypRwpkhYzCS6NEYOqJNfCrH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c05a8703-7088-4ae8-9b35-1a879db59400-0', usage_metadata={'input_tokens': 2195, 'output_tokens': 26, 'total_tokens': 2221, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "inputs = {\"messages\" : [HumanMessage(content=\"Who is the current captain of the Winnipeg Jets?\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBHnUtLSscRr"
      },
      "source": [
        "Let's look at what happened:\n",
        "\n",
        "1. Our state object was populated with our request\n",
        "2. The state object was passed into our entry point (agent node) and the agent node added an `AIMessage` to the state object and passed it along the conditional edge\n",
        "3. The conditional edge received the state object, found the \"tool_calls\" `additional_kwarg`, and sent the state object to the action node\n",
        "4. The action node added the response from the OpenAI function calling endpoint to the state object and passed it along the edge to the agent node\n",
        "5. The agent node added a response to the state object and passed it along the conditional edge\n",
        "6. The conditional edge received the state object, could not find the \"tool_calls\" `additional_kwarg` and passed the state object to END where we see it output in the cell above!\n",
        "\n",
        "Now let's look at an example that shows a multiple tool usage - all with the same flow!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afv2BuEsV5JG",
        "outputId": "ff009536-d281-4a56-c126-9cd245352bfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ntrSLPmR0QFAT87DrbJDKTOy', 'function': {'arguments': '{\"query\":\"QLoRA\"}', 'name': 'arxiv'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 236, 'total_tokens': 252, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BtLiiWyxDqlZ5FywwVVtaiKjhWMHK', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d36f596c-160a-4490-96ce-1dc77bd4ad58-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'QLoRA'}, 'id': 'call_ntrSLPmR0QFAT87DrbJDKTOy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 236, 'output_tokens': 16, 'total_tokens': 252, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "Tool Used: arxiv\n",
            "[ToolMessage(content='Published: 2023-05-23\\nTitle: QLoRA: Efficient Finetuning of Quantized LLMs\\nAuthors: Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, Luke Zettlemoyer\\nSummary: We present QLoRA, an efficient finetuning approach that reduces memory usage\\nenough to finetune a 65B parameter model on a single 48GB GPU while preserving\\nfull 16-bit finetuning task performance. QLoRA backpropagates gradients through\\na frozen, 4-bit quantized pretrained language model into Low Rank\\nAdapters~(LoRA). Our best model family, which we name Guanaco, outperforms all\\nprevious openly released models on the Vicuna benchmark, reaching 99.3% of the\\nperformance level of ChatGPT while only requiring 24 hours of finetuning on a\\nsingle GPU. QLoRA introduces a number of innovations to save memory without\\nsacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is\\ninformation theoretically optimal for normally distributed weights (b) double\\nquantization to reduce the average memory footprint by quantizing the\\nquantization constants, and (c) paged optimziers to manage memory spikes. We\\nuse QLoRA to finetune more than 1,000 models, providing a detailed analysis of\\ninstruction following and chatbot performance across 8 instruction datasets,\\nmultiple model types (LLaMA, T5), and model scales that would be infeasible to\\nrun with regular finetuning (e.g. 33B and 65B parameter models). Our results\\nshow that QLoRA finetuning on a small high-quality dataset leads to\\nstate-of-the-art results, even when using smaller models than the previous\\nSoTA. We provide a detailed analysis of chatbot performance based on both human\\nand GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable\\nalternative to human evaluation. Furthermore, we find that current chatbot\\nbenchmarks are not trustworthy to accurately evaluate the performance levels of\\nchatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to\\nChatGPT. We release all of our models and code, including CUDA kernels for\\n4-bit training.\\n\\nPublished: 2024-05-27\\nTitle: Accurate LoRA-Finetuning Quantization of LLMs via Information Retention\\nAuthors: Haotong Qin, Xudong Ma, Xingyu Zheng, Xiaoyang Li, Yang Zhang, Shouda Liu, Jie Luo, Xianglong Liu, Michele Magno\\nSummary: The LoRA-finetuning quantization of LLMs has been extensively studied to\\nobtain accurate yet compact LLMs for deployment on resource-constrained\\nhardware. However, existing methods cause the quantized LLM to severely degrade\\nand even fail to benefit from the finetuning of LoRA. This paper proposes a\\nnovel IR-QLoRA for pushing quantized LLMs with LoRA to be highly accurate\\nthrough information retention. The proposed IR-QLoRA mainly relies on two\\ntechnologies derived from the perspective of unified information: (1)\\nstatistics-based Information Calibration Quantization allows the quantized\\nparameters of LLM to retain original information accurately; (2)\\nfinetuning-based Information Elastic Connection makes LoRA utilizes elastic\\nrepresentation transformation with diverse information. Comprehensive\\nexperiments show that IR-QLoRA can significantly improve accuracy across LLaMA\\nand LLaMA2 families under 2-4 bit-widths, e.g., 4- bit LLaMA-7B achieves 1.4%\\nimprovement on MMLU compared with the state-of-the-art methods. The significant\\nperformance gain requires only a tiny 0.31% additional time consumption,\\nrevealing the satisfactory efficiency of our IR-QLoRA. We highlight that\\nIR-QLoRA enjoys excellent versatility, compatible with various frameworks\\n(e.g., NormalFloat and Integer quantization) and brings general accuracy gains.\\nThe code is available at https://github.com/htqin/ir-qlora.\\n\\nPublished: 2025-02-05\\nTitle: Resource-Efficient & Effective Code Summarization\\nAuthors: Saima Afrin, Joseph Call, Khai-Nguyen Nguyen, Oscar Chaparro, Antonio Mastropaolo\\nSummary: Code Language Models (CLMs) have demonstrated high effectiveness in\\nautomating software engineering tasks such as bug fixing, code generation, and\\ncode documentation. This ', name='arxiv', id='95278e60-34ee-4050-9067-b07cf1d438d5', tool_call_id='call_ntrSLPmR0QFAT87DrbJDKTOy')]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_QOpbBbkreQ8QBd5TFnpufaSe', 'function': {'arguments': '{\"query\": \"Tim Dettmers latest tweet\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_cA5sZrfFRwq2xtkdVNjDvnUq', 'function': {'arguments': '{\"query\": \"Artidoro Pagnoni latest tweet\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_Y6XYD2SqDukzHXBjrAui3Kba', 'function': {'arguments': '{\"query\": \"Ari Holtzman latest tweet\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_DmbDpuQnLKBdW2D8sP4Zpd88', 'function': {'arguments': '{\"query\": \"Luke Zettlemoyer latest tweet\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 1206, 'total_tokens': 1318, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BtLijVL5eqIJgbf0BcpY4XzPlOKVv', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0f80871f-983e-455f-a70a-0c62f2d5d643-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Tim Dettmers latest tweet'}, 'id': 'call_QOpbBbkreQ8QBd5TFnpufaSe', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Artidoro Pagnoni latest tweet'}, 'id': 'call_cA5sZrfFRwq2xtkdVNjDvnUq', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Ari Holtzman latest tweet'}, 'id': 'call_Y6XYD2SqDukzHXBjrAui3Kba', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Luke Zettlemoyer latest tweet'}, 'id': 'call_DmbDpuQnLKBdW2D8sP4Zpd88', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1206, 'output_tokens': 112, 'total_tokens': 1318, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "Tool Used: tavily_search_results_json\n",
            "[ToolMessage(content='[{\"title\": \"Tim Dettmers ‚Äî Making deep learning accessible.\", \"url\": \"https://timdettmers.com/\", \"content\": \"Filed Under: Academia, PhD Life Tagged With: Advisors, Grad school, PhD\\\\n\\\\n## TPUs vs GPUs for Transformers (BERT)\\\\n\\\\n2018-10-17 by Tim Dettmers 26 Comments [...] Filed Under: Deep Learning, Hardware Tagged With: AMD, CPU, High Performance Computing, Matrix Multiplication, Parallel Computing, PCIe Lanes, Sparse Training\\\\n\\\\n## LLM.int8() and Emergent Features\\\\n\\\\n2022-08-17 by Tim Dettmers 13 Comments [...] From that, I learned that quantization research is like printers. Nobody cares about printers. Nobody likes printers. But everybody is happy if printers do their job.\\\\n\\\\nFiled Under: Deep Learning Tagged With: emergent features, LLM.int8()\\\\n\\\\n## How to Choose Your Grad School\\\\n\\\\n2022-03-13 by Tim Dettmers 18 Comments\", \"score\": 0.6554468}, {\"title\": \"Tim Dettmers (@Tim_Dettmers) / X\", \"url\": \"https://twitter.com/Tim_Dettmers\", \"content\": \"Huge thank you to @NVIDIADC for gifting a brand new #NVIDIADGX B200 to CMU\\'s Catalyst Research Group! This AI supercomputing system will afford Catalyst the\", \"score\": 0.6485337}, {\"title\": \"PhD Archives - Tim Dettmers\", \"url\": \"https://timdettmers.com/tag/phd/\", \"content\": \"Filed Under: Academia, PhD Life Tagged With: Advisors, Grad school, PhD\\\\n\\\\n## Credit Assignment in Deep Learning\\\\n\\\\n2017-09-16 by Tim Dettmers 15 Comments [...] [[Read more‚Ä¶] about How to Choose Your Grad School](\\\\n\\\\nFiled Under: Academia, PhD Life Tagged With: Advisors, Grad school, PhD\\\\n\\\\n## On Creativity in Academia\\\\n\\\\n2019-09-03 by Tim Dettmers 5 Comments [...] [[Read more‚Ä¶] about On Creativity in Academia](\\\\n\\\\nFiled Under: Academia, PhD Life, Science Tagged With: PhD\\\\n\\\\n## Machine Learning PhD Applications ‚Äî Everything You Need to Know\\\\n\\\\n2018-11-26 by Tim Dettmers 154 Comments\", \"score\": 0.54710174}, {\"title\": \"Tim Dettmers - X\", \"url\": \"https://x.com/Tim_Dettmers/status/1876639222305878092\", \"content\": \"Tim Dettmers ¬∑ @Tim_Dettmers. I open Twitter, and I see this I believe we will get open-source AGI soon, but also that applying AGI will\", \"score\": 0.48703963}, {\"title\": \"About Me - Tim Dettmers\", \"url\": \"https://timdettmers.com/about/\", \"content\": \"2021                 NeurIPS 2021 Best Reviewer Award\\\\n\\\\n2018/2019      Jeff Dean ‚Äì Heidi Hopper Endowed Regental Fellowship\\\\n\\\\n2016/2017      Google Scholarship\\\\n\\\\n## Service\\\\n\\\\nReviewing:\\\\n\\\\n## Primary Sidebar\\\\n\\\\n### What to read next:\\\\n\\\\n### Recent Posts\\\\n\\\\n## Secondary Sidebar\\\\n\\\\nCopyright ¬© 2024 ¬∑ Genesis Framework ¬∑ WordPress ¬∑ Log in\\\\n\\\\n## \\\\n\\\\n## \\\\n\\\\n### [...] Convolutional 2D Knowledge Graph Embeddings, Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, Sebastian Riedel. AAAI2018. [arXiv] [bib] [code] [data] [Q&A]\\\\n\\\\n#### 2016\\\\n\\\\n8-Bit Approximations for Parallelism in Deep Learning, Tim Dettmers. ICLR2016. [arXiv] [bib] [code] [data]\\\\n\\\\n## Awards & Honors\\\\n\\\\n2023                 Madrona Prize\\\\n\\\\n2023                 Google Open Source Award\\\\n\\\\n2023                 PyTorch Foundation Award\\\\n\\\\n2023                 Martin & Beate Block Award [...] I have a PhD from University of Washington advised by Luke Zettlemoyer working on efficient deep learning at the intersection between machine learning, natural language processing, and computer systems with a focus on quantization and sparsity. My main research goal is to empower everyone to make AI their own. I do this by making large models accessible through my research (QLoRA, LLM.int8(), k-bit inference scaling laws, Petals, SWARM) and by developing software that makes it easy to use my\", \"score\": 0.42849702}]', name='tavily_search_results_json', id='5c1d4bca-0c5b-40c2-998b-3283e534c7e4', tool_call_id='call_QOpbBbkreQ8QBd5TFnpufaSe', artifact={'query': 'Tim Dettmers latest tweet', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://timdettmers.com/', 'title': 'Tim Dettmers ‚Äî Making deep learning accessible.', 'content': 'Filed Under: Academia, PhD Life Tagged With: Advisors, Grad school, PhD\\n\\n## TPUs vs GPUs for Transformers (BERT)\\n\\n2018-10-17 by Tim Dettmers 26 Comments [...] Filed Under: Deep Learning, Hardware Tagged With: AMD, CPU, High Performance Computing, Matrix Multiplication, Parallel Computing, PCIe Lanes, Sparse Training\\n\\n## LLM.int8() and Emergent Features\\n\\n2022-08-17 by Tim Dettmers 13 Comments [...] From that, I learned that quantization research is like printers. Nobody cares about printers. Nobody likes printers. But everybody is happy if printers do their job.\\n\\nFiled Under: Deep Learning Tagged With: emergent features, LLM.int8()\\n\\n## How to Choose Your Grad School\\n\\n2022-03-13 by Tim Dettmers 18 Comments', 'score': 0.6554468, 'raw_content': None}, {'url': 'https://twitter.com/Tim_Dettmers', 'title': 'Tim Dettmers (@Tim_Dettmers) / X', 'content': \"Huge thank you to @NVIDIADC for gifting a brand new #NVIDIADGX B200 to CMU's Catalyst Research Group! This AI supercomputing system will afford Catalyst the\", 'score': 0.6485337, 'raw_content': None}, {'url': 'https://timdettmers.com/tag/phd/', 'title': 'PhD Archives - Tim Dettmers', 'content': 'Filed Under: Academia, PhD Life Tagged With: Advisors, Grad school, PhD\\n\\n## Credit Assignment in Deep Learning\\n\\n2017-09-16 by Tim Dettmers 15 Comments [...] [[Read more‚Ä¶] about How to Choose Your Grad School](\\n\\nFiled Under: Academia, PhD Life Tagged With: Advisors, Grad school, PhD\\n\\n## On Creativity in Academia\\n\\n2019-09-03 by Tim Dettmers 5 Comments [...] [[Read more‚Ä¶] about On Creativity in Academia](\\n\\nFiled Under: Academia, PhD Life, Science Tagged With: PhD\\n\\n## Machine Learning PhD Applications ‚Äî Everything You Need to Know\\n\\n2018-11-26 by Tim Dettmers 154 Comments', 'score': 0.54710174, 'raw_content': None}, {'url': 'https://x.com/Tim_Dettmers/status/1876639222305878092', 'title': 'Tim Dettmers - X', 'content': 'Tim Dettmers ¬∑ @Tim_Dettmers. I open Twitter, and I see this I believe we will get open-source AGI soon, but also that applying AGI will', 'score': 0.48703963, 'raw_content': None}, {'url': 'https://timdettmers.com/about/', 'title': 'About Me - Tim Dettmers', 'content': '2021                 NeurIPS 2021 Best Reviewer Award\\n\\n2018/2019      Jeff Dean ‚Äì Heidi Hopper Endowed Regental Fellowship\\n\\n2016/2017      Google Scholarship\\n\\n## Service\\n\\nReviewing:\\n\\n## Primary Sidebar\\n\\n### What to read next:\\n\\n### Recent Posts\\n\\n## Secondary Sidebar\\n\\nCopyright ¬© 2024 ¬∑ Genesis Framework ¬∑ WordPress ¬∑ Log in\\n\\n## \\n\\n## \\n\\n### [...] Convolutional 2D Knowledge Graph Embeddings, Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, Sebastian Riedel. AAAI2018. [arXiv] [bib] [code] [data] [Q&A]\\n\\n#### 2016\\n\\n8-Bit Approximations for Parallelism in Deep Learning, Tim Dettmers. ICLR2016. [arXiv] [bib] [code] [data]\\n\\n## Awards & Honors\\n\\n2023                 Madrona Prize\\n\\n2023                 Google Open Source Award\\n\\n2023                 PyTorch Foundation Award\\n\\n2023                 Martin & Beate Block Award [...] I have a PhD from University of Washington advised by Luke Zettlemoyer working on efficient deep learning at the intersection between machine learning, natural language processing, and computer systems with a focus on quantization and sparsity. My main research goal is to empower everyone to make AI their own. I do this by making large models accessible through my research (QLoRA, LLM.int8(), k-bit inference scaling laws, Petals, SWARM) and by developing software that makes it easy to use my', 'score': 0.42849702, 'raw_content': None}], 'response_time': 3.5}), ToolMessage(content='[{\"title\": \"Artidoro Pagnoni: Ciao!\", \"url\": \"https://artidoro.github.io/\", \"content\": \"Artidoro Pagnoni\\\\n\\\\n### Artidoro Pagnoni\\\\n\\\\nPhD student in NLP at the University of Washington\\\\n\\\\n# Ciao!\\\\n\\\\nI am a final-year PhD student in Computer Science at the University of Washington, advised by Luke Zettlemoyer, and a visiting researcher at Meta. My research focuses on resource efficiency and improving LLM scaling trends. [...] I have recently developed the Byte Latent Transformer, a new architecture that efficiently learns from raw byte data unlocking a new scaling dimension and paving the path towards universal byte models. With QLoRA, I reduced finetuning memory requirements by 15x and showed how to approach ChatGPT 3.5 performance in 24h on a single GPU. [...] Previously, I have also worked on sythetic data augmentation for improved controllability of generation systems, investigated language models‚Äô reasoning and world modeling abilities, and evaluated their factual errors, as well as societal challenge associated with their use.\", \"score\": 0.6490677}, {\"title\": \"Highlights by Artidoro Pagnoni (@ArtidoroPagnoni) / X\", \"url\": \"https://twitter.com/ArtidoroPagnoni/highlights\", \"content\": \"Artidoro Pagnoni\\'s Highlights ... Introducing the Byte Latent Transformer (BLT) ‚Äì An LLM architecture that scales better than Llama 3 using byte-patches instead\", \"score\": 0.64719695}, {\"title\": \"Artidoro Pagnoni (@ApagnoniPagnoni) / X\", \"url\": \"https://twitter.com/apagnonipagnoni?lang=ms\", \"content\": \"Siaran Artidoro Pagnoni. Artidoro Pagnoni ... My favorite shot from the last rocket landing attempt on the droneship. Imej.\", \"score\": 0.6102915}, {\"title\": \"Artidoro Pagnoni (@ArtidoroPagnoni) / X\", \"url\": \"https://twitter.com/ArtidoroPagnoni\", \"content\": \"Artidoro Pagnoni\\'s posts ... Introducing the Byte Latent Transformer (BLT) ‚Äì An LLM architecture that scales better than Llama 3 using byte-patches instead of\", \"score\": 0.6100127}, {\"title\": \"Artidoro Pagnoni - Hugging Face\", \"url\": \"https://huggingface.co/artidoro/activity/all\", \"content\": \"Hugging Face\\'s logo\\\\nArtidoro Pagnoni\\'s picture\\\\n\\\\n# Artidoro Pagnoni\\\\n\\\\n### AI & ML interests\\\\n\\\\n### Recent Activity\\\\n\\\\n### Organizations\\\\n\\\\nUniversity of Washington NLP\\'s profile picture\\\\n\\\\n## artidoro\\'s activity\\\\n\\\\n#### allenai/DataDecide-ppl-results\\\\n\\\\n#### facebook/blt\\\\n\\\\n#### SuperBPE: Space Travel for Language Models\\\\n\\\\n#### Byte Latent Transformer: Patches Scale Better Than Tokens\\\\n\\\\n#### Socratic Pretraining: Question-Driven Pretraining for Controllable Summarization [...] #### Byte Latent Transformer: Patches Scale Better Than Tokens\\\\n\\\\n#### Byte Latent Transformer: Patches Scale Better Than Tokens\\\\n\\\\n#### artidoro/model-tvergho\\\\n\\\\n#### artidoro/model-vinaic\\\\n\\\\n#### artidoro/model-vinaia\\\\n\\\\n#### meta-llama/Llama-2-7b\\\\n\\\\n#### Error trying to submit LLaMA 2 base model\\\\n\\\\n#### uwnlp/llama-2-70b-qlora-openorca\\\\n\\\\n#### TheBloke/llama-2-70b-Guanaco-QLoRA-fp16\\\\n\\\\n#### timdettmers/guanaco-33b\\\\n\\\\n#### did it stop working?\\\\n\\\\n#### How to fine-tune the Guanaco (7B, 13B) model? [...] #### timdettmers/openassistant-guanaco\\\\n\\\\n#### Guanaco-13B\", \"score\": 0.34277}]', name='tavily_search_results_json', id='f3d83fc6-69b1-450f-9cf7-e1fec6153697', tool_call_id='call_cA5sZrfFRwq2xtkdVNjDvnUq', artifact={'query': 'Artidoro Pagnoni latest tweet', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://artidoro.github.io/', 'title': 'Artidoro Pagnoni: Ciao!', 'content': 'Artidoro Pagnoni\\n\\n### Artidoro Pagnoni\\n\\nPhD student in NLP at the University of Washington\\n\\n# Ciao!\\n\\nI am a final-year PhD student in Computer Science at the University of Washington, advised by Luke Zettlemoyer, and a visiting researcher at Meta. My research focuses on resource efficiency and improving LLM scaling trends. [...] I have recently developed the Byte Latent Transformer, a new architecture that efficiently learns from raw byte data unlocking a new scaling dimension and paving the path towards universal byte models. With QLoRA, I reduced finetuning memory requirements by 15x and showed how to approach ChatGPT 3.5 performance in 24h on a single GPU. [...] Previously, I have also worked on sythetic data augmentation for improved controllability of generation systems, investigated language models‚Äô reasoning and world modeling abilities, and evaluated their factual errors, as well as societal challenge associated with their use.', 'score': 0.6490677, 'raw_content': None}, {'url': 'https://twitter.com/ArtidoroPagnoni/highlights', 'title': 'Highlights by Artidoro Pagnoni (@ArtidoroPagnoni) / X', 'content': \"Artidoro Pagnoni's Highlights ... Introducing the Byte Latent Transformer (BLT) ‚Äì An LLM architecture that scales better than Llama 3 using byte-patches instead\", 'score': 0.64719695, 'raw_content': None}, {'url': 'https://twitter.com/apagnonipagnoni?lang=ms', 'title': 'Artidoro Pagnoni (@ApagnoniPagnoni) / X', 'content': 'Siaran Artidoro Pagnoni. Artidoro Pagnoni ... My favorite shot from the last rocket landing attempt on the droneship. Imej.', 'score': 0.6102915, 'raw_content': None}, {'url': 'https://twitter.com/ArtidoroPagnoni', 'title': 'Artidoro Pagnoni (@ArtidoroPagnoni) / X', 'content': \"Artidoro Pagnoni's posts ... Introducing the Byte Latent Transformer (BLT) ‚Äì An LLM architecture that scales better than Llama 3 using byte-patches instead of\", 'score': 0.6100127, 'raw_content': None}, {'url': 'https://huggingface.co/artidoro/activity/all', 'title': 'Artidoro Pagnoni - Hugging Face', 'content': \"Hugging Face's logo\\nArtidoro Pagnoni's picture\\n\\n# Artidoro Pagnoni\\n\\n### AI & ML interests\\n\\n### Recent Activity\\n\\n### Organizations\\n\\nUniversity of Washington NLP's profile picture\\n\\n## artidoro's activity\\n\\n#### allenai/DataDecide-ppl-results\\n\\n#### facebook/blt\\n\\n#### SuperBPE: Space Travel for Language Models\\n\\n#### Byte Latent Transformer: Patches Scale Better Than Tokens\\n\\n#### Socratic Pretraining: Question-Driven Pretraining for Controllable Summarization [...] #### Byte Latent Transformer: Patches Scale Better Than Tokens\\n\\n#### Byte Latent Transformer: Patches Scale Better Than Tokens\\n\\n#### artidoro/model-tvergho\\n\\n#### artidoro/model-vinaic\\n\\n#### artidoro/model-vinaia\\n\\n#### meta-llama/Llama-2-7b\\n\\n#### Error trying to submit LLaMA 2 base model\\n\\n#### uwnlp/llama-2-70b-qlora-openorca\\n\\n#### TheBloke/llama-2-70b-Guanaco-QLoRA-fp16\\n\\n#### timdettmers/guanaco-33b\\n\\n#### did it stop working?\\n\\n#### How to fine-tune the Guanaco (7B, 13B) model? [...] #### timdettmers/openassistant-guanaco\\n\\n#### Guanaco-13B\", 'score': 0.34277, 'raw_content': None}], 'response_time': 3.54}), ToolMessage(content='[{\"title\": \"Ari Holtzman - X\", \"url\": \"https://x.com/universeinanegg/status/1943036107970453942\", \"content\": \"Ari Holtzman ¬∑ @universeinanegg. Some thought experiments on what if we keep ignoring prompt science: 1 ... 7:54 PM ¬∑ Jul 9, 2025. ¬∑. 54. Views.\", \"score\": 0.6867278}, {\"title\": \"Ari Holtzman on X: \\\\\"Was such a blast to write this with ...\", \"url\": \"https://twitter.com/universeinanegg/status/1943036113183998086\", \"content\": \"@ChenhaoTan ! And thank you to. @PeterWestTM. for many useful conversations as we were putting the argument together! 7:54 PM ¬∑ Jul 9, 2025. ¬∑. 65. Views.\", \"score\": 0.6334335}, {\"title\": \"Ari Holtzman | CDS\", \"url\": \"https://codas.uchicago.edu/people/ari-holtzman/\", \"content\": \"Logo\\\\n Logo\\\\n\\\\n# Ari Holtzman\\\\n\\\\nAri is an incoming Assistant Professor of Computer Science and Data Science, starting July 2024. [...] His research has focused broadly on generative models of text: how we can use them and how can we understand them better. His research interests have spanned everything from dialogue, including winning the first Amazon Alexa Prize in 2017, to fundamental research on text generation, such as proposing Nucleus Sampling, a decoding algorithm used broadly in deployed systems such as the OpenAI API. With the new wave of powerful generative models being continually released, Ari has argued for using [...] the lens of Complex Systems to understand generative models of human media, suggesting that a lack of precise behavioral vocabulary to describe what language models are doing is the bottleneck to explaining how language models are capable of such impressive performance on a range of tasks. He completed his PhD in Computer Science at the University of Washington studying ‚ÄúInterpretation Errors‚Äù in how we understand generative models after an interdisciplinary degree at NYU combining Computer\", \"score\": 0.531672}, {\"title\": \"Ari Holtzman ‚Äì Department of Computer Science\", \"url\": \"https://cs.uchicago.edu/people/ari-holtzman/\", \"content\": \"### Diversity @ UChicago CS\\\\n\\\\nAt UChicago CS, we welcome students of all backgrounds and identities.\\\\n\\\\n### Our BPC Plan\\\\n\\\\nFostering an inclusive environment where students from all backgrounds can achieve their highest potential.\\\\n\\\\n### News\\\\n\\\\n### PhD Candidate Bogdan Stoica Receives Distinguished Artifact Evaluator Award for Championing Reproducibility in Computer Science\\\\n\\\\n### Report from GlobusWorld 2025: Going Beyond Data\\\\n\\\\nheadshots [...] ### Research\\\\n\\\\n### Systems, Architecture & Networking\\\\n\\\\n### Awards & Honors\\\\n\\\\n### Get Updates\\\\n\\\\n### Follow [...] ### University of Chicago PhD Graduates Secure Tenure-Track Faculty Positions Amid a Competitive Job Market\\\\n\\\\n### Events\\\\n\\\\n### Video\\\\n\\\\nfuture of AI panelists\\\\n\\\\n### The Future of AI Panel: Alumni Weekend\\\\n\\\\n### Can we authenticate human creativity?\\\\n\\\\nheadshot\\\\n\\\\n### AI and the Future of Work Panel: Featuring Nick Feamster\\\\n\\\\nheadhsot\\\\nheadhsot\\\\n\\\\n# Ari Holtzman\", \"score\": 0.4296453}, {\"title\": \"Ari Holtzman\", \"url\": \"https://x.com/universeinanegg?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor\", \"content\": \"Prompting is our most successful tool for exploring LLMs, but the term evokes eye-rolls and grimaces from scientists. Why? Because prompting as scientific inquiry has become conflated with prompt engineering. This is holding us back. üßµand new paper: arxiv.org/abs/2507.00163\", \"score\": 0.4066976}]', name='tavily_search_results_json', id='b4a1d9f0-85e2-4ae4-8637-22d807a70066', tool_call_id='call_Y6XYD2SqDukzHXBjrAui3Kba', artifact={'query': 'Ari Holtzman latest tweet', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://x.com/universeinanegg/status/1943036107970453942', 'title': 'Ari Holtzman - X', 'content': 'Ari Holtzman ¬∑ @universeinanegg. Some thought experiments on what if we keep ignoring prompt science: 1 ... 7:54 PM ¬∑ Jul 9, 2025. ¬∑. 54. Views.', 'score': 0.6867278, 'raw_content': None}, {'url': 'https://twitter.com/universeinanegg/status/1943036113183998086', 'title': 'Ari Holtzman on X: \"Was such a blast to write this with ...', 'content': '@ChenhaoTan ! And thank you to. @PeterWestTM. for many useful conversations as we were putting the argument together! 7:54 PM ¬∑ Jul 9, 2025. ¬∑. 65. Views.', 'score': 0.6334335, 'raw_content': None}, {'url': 'https://codas.uchicago.edu/people/ari-holtzman/', 'title': 'Ari Holtzman | CDS', 'content': 'Logo\\n Logo\\n\\n# Ari Holtzman\\n\\nAri is an incoming Assistant Professor of Computer Science and Data Science, starting July 2024. [...] His research has focused broadly on generative models of text: how we can use them and how can we understand them better. His research interests have spanned everything from dialogue, including winning the first Amazon Alexa Prize in 2017, to fundamental research on text generation, such as proposing Nucleus Sampling, a decoding algorithm used broadly in deployed systems such as the OpenAI API. With the new wave of powerful generative models being continually released, Ari has argued for using [...] the lens of Complex Systems to understand generative models of human media, suggesting that a lack of precise behavioral vocabulary to describe what language models are doing is the bottleneck to explaining how language models are capable of such impressive performance on a range of tasks. He completed his PhD in Computer Science at the University of Washington studying ‚ÄúInterpretation Errors‚Äù in how we understand generative models after an interdisciplinary degree at NYU combining Computer', 'score': 0.531672, 'raw_content': None}, {'url': 'https://cs.uchicago.edu/people/ari-holtzman/', 'title': 'Ari Holtzman ‚Äì Department of Computer Science', 'content': '### Diversity @ UChicago CS\\n\\nAt UChicago CS, we welcome students of all backgrounds and identities.\\n\\n### Our BPC Plan\\n\\nFostering an inclusive environment where students from all backgrounds can achieve their highest potential.\\n\\n### News\\n\\n### PhD Candidate Bogdan Stoica Receives Distinguished Artifact Evaluator Award for Championing Reproducibility in Computer Science\\n\\n### Report from GlobusWorld 2025: Going Beyond Data\\n\\nheadshots [...] ### Research\\n\\n### Systems, Architecture & Networking\\n\\n### Awards & Honors\\n\\n### Get Updates\\n\\n### Follow [...] ### University of Chicago PhD Graduates Secure Tenure-Track Faculty Positions Amid a Competitive Job Market\\n\\n### Events\\n\\n### Video\\n\\nfuture of AI panelists\\n\\n### The Future of AI Panel: Alumni Weekend\\n\\n### Can we authenticate human creativity?\\n\\nheadshot\\n\\n### AI and the Future of Work Panel: Featuring Nick Feamster\\n\\nheadhsot\\nheadhsot\\n\\n# Ari Holtzman', 'score': 0.4296453, 'raw_content': None}, {'url': 'https://x.com/universeinanegg?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor', 'title': 'Ari Holtzman', 'content': 'Prompting is our most successful tool for exploring LLMs, but the term evokes eye-rolls and grimaces from scientists. Why? Because prompting as scientific inquiry has become conflated with prompt engineering. This is holding us back. üßµand new paper: arxiv.org/abs/2507.00163', 'score': 0.4066976, 'raw_content': None}], 'response_time': 2.7}), ToolMessage(content='[{\"title\": \"Luke Zettlemoyer (@LukeZettlemoyer) / X\", \"url\": \"https://x.com/lukezettlemoyer?lang=en\", \"content\": \"Introducing FlexOlmo, a new paradigm for language model training that enables the co-development of AI through data collaboration.. Embedded video. 0:34.\", \"score\": 0.61834323}, {\"title\": \"Luke Zettlemoyer - University of Washington\", \"url\": \"https://homes.cs.washington.edu/~lsz/\", \"content\": \"Jun 6, 2025: I gave a talk on mixed-modal LMs at the Frontiers in NeuroAI workshop at the Kempner Institute. Feb 11, 2025: Congratulations to Chunting and Lili and the Tranfusion team for getting an oral at ICLR 2025! Dec 3, 2024: Elected ACL President (2025 VP Elect; 2026 VP; 2027 Pres; 2028 Past Pres) Aug 11, 2024: Congrats to OLMo team for winning a Best Theme Paper Award at ACL 2024! Aug 11, 2024: Congrats to Dolma team for winning a Best Resource Paper Award at ACL 2024! Jan 15, 2024: [...] Congratulations to Xian and team for getting oral at ICLR 2024 for their work on instruction backtranslation! Oct 10, 2023: I was on the twiml podcast, Episode 650 Sep 21, 2023: Congrauations to Tim and Arti for the QLoRA paper getting an oral at NeurIPS 2023! Sep 21, 2023: Congrauations to Timo and team on the Toolformer paper getting an oral at NeurIPS 2023! Jul 24, 2023: I was on The Thesis Review with Sean Welleck Episode 45 Jan 6, 2022: I was named an ACL Fellow! [...] ACL Fellow (2021), as well as winning a PECASE award (2016), an Allen Distinguished Investigator award (2014), and many best paper awards. I was an undergraduate at NC State, recieved my PhD from MIT, and was a postdocal researcher at the University of Edinburgh.\", \"score\": 0.6161283}, {\"title\": \"Luke Zettlemoyer - X\", \"url\": \"https://x.com/LukeZettlemoyer/status/1003662931479941120?lang=ar-x-fm\", \"content\": \"Luke Zettlemoyer ¬∑ @LukeZettlemoyer. Come see Julian Michael presenting his work in question answer meaning representations, now at @NAACLHLT\", \"score\": 0.5530473}, {\"title\": \"Posts with replies by Luke Zettlemoyer (@LukeZettlemoyer) / X\", \"url\": \"https://twitter.com/LukeZettlemoyer/with_replies\", \"content\": \"Joined September 2015. 2,120 Following ¬∑ 9,556 Followers ¬∑ Posts ¬∑ Replies ¬∑ Media. @LukeZettlemoyer hasn\\'t posted. When they do, their posts will show up\", \"score\": 0.37855154}, {\"title\": \"Luke Zettlemoyer - Google Scholar\", \"url\": \"https://scholar.google.com/citations?user=UjpbO6IAAAAJ&hl=en\", \"content\": \"New articles by this author. New citations to this author. New articles related to this author\\'s research. Email address for updates ... Luke Zettlemoyer.\", \"score\": 0.2979196}]', name='tavily_search_results_json', id='d329aec6-755c-400d-81db-2381d0287947', tool_call_id='call_DmbDpuQnLKBdW2D8sP4Zpd88', artifact={'query': 'Luke Zettlemoyer latest tweet', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://x.com/lukezettlemoyer?lang=en', 'title': 'Luke Zettlemoyer (@LukeZettlemoyer) / X', 'content': 'Introducing FlexOlmo, a new paradigm for language model training that enables the co-development of AI through data collaboration.. Embedded video. 0:34.', 'score': 0.61834323, 'raw_content': None}, {'url': 'https://homes.cs.washington.edu/~lsz/', 'title': 'Luke Zettlemoyer - University of Washington', 'content': 'Jun 6, 2025: I gave a talk on mixed-modal LMs at the Frontiers in NeuroAI workshop at the Kempner Institute. Feb 11, 2025: Congratulations to Chunting and Lili and the Tranfusion team for getting an oral at ICLR 2025! Dec 3, 2024: Elected ACL President (2025 VP Elect; 2026 VP; 2027 Pres; 2028 Past Pres) Aug 11, 2024: Congrats to OLMo team for winning a Best Theme Paper Award at ACL 2024! Aug 11, 2024: Congrats to Dolma team for winning a Best Resource Paper Award at ACL 2024! Jan 15, 2024: [...] Congratulations to Xian and team for getting oral at ICLR 2024 for their work on instruction backtranslation! Oct 10, 2023: I was on the twiml podcast, Episode 650 Sep 21, 2023: Congrauations to Tim and Arti for the QLoRA paper getting an oral at NeurIPS 2023! Sep 21, 2023: Congrauations to Timo and team on the Toolformer paper getting an oral at NeurIPS 2023! Jul 24, 2023: I was on The Thesis Review with Sean Welleck Episode 45 Jan 6, 2022: I was named an ACL Fellow! [...] ACL Fellow (2021), as well as winning a PECASE award (2016), an Allen Distinguished Investigator award (2014), and many best paper awards. I was an undergraduate at NC State, recieved my PhD from MIT, and was a postdocal researcher at the University of Edinburgh.', 'score': 0.6161283, 'raw_content': None}, {'url': 'https://x.com/LukeZettlemoyer/status/1003662931479941120?lang=ar-x-fm', 'title': 'Luke Zettlemoyer - X', 'content': 'Luke Zettlemoyer ¬∑ @LukeZettlemoyer. Come see Julian Michael presenting his work in question answer meaning representations, now at @NAACLHLT', 'score': 0.5530473, 'raw_content': None}, {'url': 'https://twitter.com/LukeZettlemoyer/with_replies', 'title': 'Posts with replies by Luke Zettlemoyer (@LukeZettlemoyer) / X', 'content': \"Joined September 2015. 2,120 Following ¬∑ 9,556 Followers ¬∑ Posts ¬∑ Replies ¬∑ Media. @LukeZettlemoyer hasn't posted. When they do, their posts will show up\", 'score': 0.37855154, 'raw_content': None}, {'url': 'https://scholar.google.com/citations?user=UjpbO6IAAAAJ&hl=en', 'title': 'Luke Zettlemoyer - Google Scholar', 'content': \"New articles by this author. New citations to this author. New articles related to this author's research. Email address for updates ... Luke Zettlemoyer.\", 'score': 0.2979196, 'raw_content': None}], 'response_time': 3.97})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='Here are the latest tweets or relevant updates from the authors of the QLoRA paper:\\n\\n1. **Tim Dettmers**:\\n   - [Latest Tweet](https://twitter.com/Tim_Dettmers): \"Huge thank you to @NVIDIADC for gifting a brand new #NVIDIADGX B200 to CMU\\'s Catalyst Research Group! This AI supercomputing system will afford Catalyst the...\"\\n\\n2. **Artidoro Pagnoni**:\\n   - [Latest Tweet](https://twitter.com/ArtidoroPagnoni): \"Introducing the Byte Latent Transformer (BLT) ‚Äì An LLM architecture that scales better than Llama 3 using byte-patches instead...\"\\n\\n3. **Ari Holtzman**:\\n   - [Latest Tweet](https://twitter.com/universeinanegg/status/1943036113183998086): \"Was such a blast to write this with @ChenhaoTan! And thank you to @PeterWestTM for many useful conversations as we were putting the argument together!\"\\n\\n4. **Luke Zettlemoyer**:\\n   - [Latest Tweet](https://x.com/lukezettlemoyer?lang=en): \"Introducing FlexOlmo, a new paradigm for language model training that enables the co-development of AI through data collaboration.. Embedded video. 0:34.\"\\n\\nThese links will take you to their respective Twitter profiles or tweets for more details.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 291, 'prompt_tokens': 4907, 'total_tokens': 5198, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BtLiphgbEOy5jq79j2ets5Ws5xcsz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d338dff4-5741-4e11-9f06-f4266e0212ae-0', usage_metadata={'input_tokens': 4907, 'output_tokens': 291, 'total_tokens': 5198, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"Search Arxiv for the QLoRA paper, then search each of the authors to find out their latest Tweet using Tavily!\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        if node == \"action\":\n",
        "          print(f\"Tool Used: {values['messages'][0].name}\")\n",
        "        print(values[\"messages\"])\n",
        "\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wiki tool - from node: agent\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_IKjBt7PJsNV8A8Lf1Fp9LXQk', 'function': {'arguments': '{\"query\":\"LangChain\"}', 'name': 'wikipedia'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 220, 'total_tokens': 234, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BtLjV7lJaM1E7P0kuGNsqGso2WqIB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--46f79e82-aeea-49a3-92d1-c070e1696f5f-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'LangChain'}, 'id': 'call_IKjBt7PJsNV8A8Lf1Fp9LXQk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 220, 'output_tokens': 14, 'total_tokens': 234, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "Wiki tool - from node: action\n",
            "[ToolMessage(content='Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Model Context Protocol\\nSummary: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts. Following its announcement, the protocol was adopted by major AI providers, including OpenAI and Google DeepMind.\\n\\n\\n\\nPage: Intelligent agent\\nSummary: In artificial intelligence, an intelligent agent is an entity that perceives its environment, takes actions autonomously to achieve goals, and may improve its performance through machine learning or by acquiring knowledge. AI textbooks define artificial intelligence as the \"study and design of intelligent agents,\" emphasizing that goal-directed behavior is central to intelligence.\\nA specialized subset of intelligent agents, agentic AI (also known as an AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods.\\nIntelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria‚Äîsuch as a firm, a state, or a biome.\\nIntelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion. For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior. Similarly, an evolutionary algorithm\\'s behavior is guided by a fitness function.\\nIntelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations.\\nIntelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents‚Äîautonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a \"rational agent\".\\n\\n', name='wikipedia', id='19716d0d-78a7-4ecb-9f74-af5c84c7ae5e', tool_call_id='call_IKjBt7PJsNV8A8Lf1Fp9LXQk')]\n",
            "\n",
            "\n",
            "Wiki tool - from node: agent\n",
            "[AIMessage(content='LangChain is a software framework designed to facilitate the integration of large language models (LLMs) into various applications. It supports use-cases similar to those of language models, including document analysis and summarization, chatbots, and code analysis.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 770, 'total_tokens': 820, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BtLjYeqo0GjDWLcbPJ3YBgsrByaJu', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3c0b7ba3-0fcf-47e4-992c-485751932176-0', usage_metadata={'input_tokens': 770, 'output_tokens': 50, 'total_tokens': 820, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# üìö Test: Wikipedia tool\n",
        "wiki_test = {\"messages\": [HumanMessage(content=\"Give a short summary about LangChain from Wikipedia.\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(wiki_test, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Wiki tool - from node: {node}\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXzDlZVz1Hnf"
      },
      "source": [
        "#### üèóÔ∏è Activity #2:\n",
        "\n",
        "Please write out the steps the agent took to arrive at the correct answer.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Based on the test output, here are the steps the agent took to provide information about LangChain:\n",
        "\n",
        "1. **Initial Processing (Agent Node)**: The agent received the user's question about LangChain and determined it needed to use a tool to gather information. It generated a tool call for the `wikipedia` function with the query \"LangChain\".\n",
        "\n",
        "2. **Tool Execution (Action Node)**: The system executed the Wikipedia tool, which searched for and returned relevant information about LangChain from Wikipedia.\n",
        "\n",
        "3. **Final Response (Agent Node)**: The agent received the tool result and formulated a natural language response summarizing LangChain as \"a software framework designed to facilitate the integration of large language models (LLMs) into various applications.\"\n",
        "\n",
        "4. **Completion**: Since there were no more tool calls needed and the response was complete, the conditional edge directed the flow to END, finishing the conversation.\n",
        "\n",
        "**Summary of the flow**: User Input ‚Üí Agent (tool call) ‚Üí Action (execute Wikipedia tool) ‚Üí Agent (final response) ‚Üí END\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ù Breakout Room #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7c8-Uyarh1v"
      },
      "source": [
        "## Part 1: LangSmith Evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV3XeFOT1Sar"
      },
      "source": [
        "### Pre-processing for LangSmith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wruQCuzewUuO"
      },
      "source": [
        "To do a little bit more preprocessing, let's wrap our LangGraph agent in a simple chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "oeXdQgbxwhTv"
      },
      "outputs": [],
      "source": [
        "def convert_inputs(input_object):\n",
        "  return {\"messages\" : [HumanMessage(content=input_object[\"question\"])]}\n",
        "\n",
        "def parse_output(input_state):\n",
        "  return input_state[\"messages\"][-1].content\n",
        "\n",
        "agent_chain_with_formatting = convert_inputs | simple_agent_graph | parse_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "orYxBZXSxJjZ",
        "outputId": "76be837b-6424-4516-8f63-07fbd8c25bf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The expression \\\\((5 + 3) * 2\\\\) can be solved by following the order of operations, which is parentheses first, then multiplication.\\n\\n1. Calculate the expression inside the parentheses: \\\\(5 + 3 = 8\\\\).\\n2. Multiply the result by 2: \\\\(8 * 2 = 16\\\\).\\n\\nSo, \\\\((5 + 3) * 2 = 16\\\\).'"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_chain_with_formatting.invoke({\"question\" : \"What is RAG?\"})\n",
        "agent_chain_with_formatting.invoke({\n",
        "    \"question\": \"Summarize the Wikipedia entry for OpenAI.\"\n",
        "})\n",
        "agent_chain_with_formatting.invoke({\n",
        "    \"question\": \"What is (5 + 3) * 2?\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9UkCIqkpyZu"
      },
      "source": [
        "### Task 1: Creating An Evaluation Dataset\n",
        "\n",
        "Just as we saw last week, we'll want to create a dataset to test our Agent's ability to answer questions.\n",
        "\n",
        "In order to do this - we'll want to provide some questions and some answers. Let's look at how we can create such a dataset below.\n",
        "\n",
        "```python\n",
        "questions = [\n",
        "    \"What optimizer is used in QLoRA?\",\n",
        "    \"What data type was created in the QLoRA paper?\",\n",
        "    \"What is a Retrieval Augmented Generation system?\",\n",
        "    \"Who authored the QLoRA paper?\",\n",
        "    \"What is the most popular deep learning framework?\",\n",
        "    \"What significant improvements does the LoRA system make?\",\n",
        "    \"What is the result of 3 * (7 + 1)?\",\n",
        "    \"Summarize the Wikipedia entry for OpenAI.\"        \n",
        "]\n",
        "\n",
        "answers = [\n",
        "    {\"must_mention\" : [\"paged\", \"optimizer\"]},\n",
        "    {\"must_mention\" : [\"NF4\", \"NormalFloat\"]},\n",
        "    {\"must_mention\" : [\"ground\", \"context\"]},\n",
        "    {\"must_mention\" : [\"Tim\", \"Dettmers\"]},\n",
        "    {\"must_mention\" : [\"PyTorch\", \"TensorFlow\"]},\n",
        "    {\"must_mention\" : [\"reduce\", \"parameters\"]},\n",
        "    {\"must_mention\": [\"24\"]}, \n",
        "    {\"must_mention\": [\"OpenAI\", \"research\"]} \n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfMXF2KAsQxs"
      },
      "source": [
        "#### üèóÔ∏è Activity #3:\n",
        "\n",
        "Please create a dataset in the above format with at least 5 questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "CbagRuJop83E"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"What optimizer is used in QLoRA?\",\n",
        "    \"What data type was created in the QLoRA paper?\",\n",
        "    \"What is a Retrieval Augmented Generation system?\",\n",
        "    \"Who authored the QLoRA paper?\",\n",
        "    \"What is the most popular deep learning framework?\",\n",
        "    \"What significant improvements does the LoRA system make?\",\n",
        "    \"Summarize the Wikipedia entry for OpenAI.\"  \n",
        "]\n",
        "\n",
        "answers = [\n",
        "    {\"must_mention\" : [\"paged\", \"optimizer\"]},\n",
        "    {\"must_mention\" : [\"NF4\", \"NormalFloat\"]},\n",
        "    {\"must_mention\" : [\"ground\", \"context\"]},\n",
        "    {\"must_mention\" : [\"Tim\", \"Dettmers\"]},\n",
        "    {\"must_mention\" : [\"PyTorch\", \"TensorFlow\"]},\n",
        "    {\"must_mention\" : [\"reduce\", \"parameters\"]},\n",
        "    {\"must_mention\": [\"OpenAI\", \"research\"]} \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_j2gKRA8irhzWgIj8t6mm8U5I', 'function': {'arguments': '{\"query\":\"current captain of the Winnipeg Jets 2023\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 220, 'total_tokens': 246, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BtLkbGy3ZZZ9B3QpRZIzelE1OJOg9', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--38cd9af7-a948-4ea9-b8ef-8375f1aa4710-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current captain of the Winnipeg Jets 2023'}, 'id': 'call_j2gKRA8irhzWgIj8t6mm8U5I', 'type': 'tool_call'}], usage_metadata={'input_tokens': 220, 'output_tokens': 26, 'total_tokens': 246, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='[{\"title\": \"Adam Lowry - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/Adam_Lowry\", \"content\": \"| Awards and achievements | | |\\\\n| --- | --- | --- |\\\\n| Preceded by Stefan Elliott | Winner of the Daryl K. (Doc) Seaman Trophy_Seaman_Trophy \\\\\"Daryl K. (Doc) Seaman Trophy\\\\\")  2010 | Succeeded by Colin Smith \\\\\"Colin Smith (ice hockey)\\\\\") |\\\\n| Sporting positions | | |\\\\n| Preceded by Blake Wheeler | Winnipeg Jets captain  2023‚Äìpresent | Incumbent | [...] Entering the 2023‚Äì24 season, Lowry was named captain of the Jets on September 12, 2023. He became the third in the team\\'s history since relocating to Winnipeg, and the tenth overall in franchise history.\\\\n\\\\nOn May 4, 2025, Lowry scored at 16:10 in double overtime to win 4-3 against the St. Louis Blues in Game 7 of the Jets-Blues first round playoff series.\\\\n\\\\n## Personal life [...] Adam Lowry (born March 29, 1993) is an American-born Canadian professional ice hockey centre \\\\\"Center (ice hockey)\\\\\") and  captain \\\\\"Captain (ice hockey)\\\\\") of the Winnipeg Jets of the National Hockey League (NHL).\\\\n\\\\n## Early life\", \"score\": 0.8896154}, {\"title\": \"Adam Lowry named Jets captain | Winnipeg Jets - NHL.com\", \"url\": \"https://www.nhl.com/jets/news/adam-lowry-named-jets-captain\", \"content\": \"The 30-year-old wore an √¢\\x80\\x9cA√¢\\x80\\x9d for the first time in 2022-23 along with Josh Morrissey and Mark Scheifele who will both serve as alternates for the team this year. The Jets didn√¢\\x80\\x99t have a captain last season as head coach Rick Bowness and his staff wanted more voices in the dressing room.\\\\n\\\\n√¢\\x80\\x9cIt went well last year. Mark, Adam and Josh did a great job in the room which is what we wanted. We all know Adam is the first guy on the ice to stick up for his teammates,√¢\\x80\\x9d said Bowness. [...] √¢\\x80\\x9cHe√¢\\x80\\x99s a true professional, he has total respect from every player on the team, every player around the league and certainly from the coaching staff as well. We just feel at this point it√¢\\x80\\x99s the right time to name Adam as our captain.√¢\\x80\\x9d [...] √¢\\x80\\x9cGetting to be a captain of a Canadian NHL team is pretty special and something I√¢\\x80\\x99m really looking forward too.√¢\\x80\\x9d\", \"score\": 0.85509074}, {\"title\": \"Winnipeg Jets 2023-24 roster and scoring statistics at hockeydb.com\", \"url\": \"https://www.hockeydb.com/ihdb/stats/leagues/seasons/teams/0063782024.html\", \"content\": \"| 2 | Dylan DeMelo | D | 82 | 3 | 28 | 31 | 36 | 46 | 5 | 0 | 1 | 1 | 2 | ONT: London | 30 |\\\\n| 9 | Alex Iafallo | L | 82 | 11 | 16 | 27 | 6 | 14 | 5 | 0 | 1 | 1 | 0 | NY: Eden | 29 |\\\\n| 23 | Sean Monahan 1 | C | 34 | 13 | 11 | 24 | 2 | 9 | 5 | 0 | 1 | 1 | 0 | ONT: Brampton | 28 |\\\\n| 5 | Brenden Dillon | D | 77 | 8 | 12 | 20 | 92 | 20 | 3 | 0 | 3 | 3 | 4 | BC: New Westminster | 32 |\\\\n| 36 | Morgan Barron | C | 80 | 11 | 7 | 18 | 23 | 10 | -- | -- | -- | -- | -- | NS: Halifax | 24 | [...] | 54 | Dylan Samberg | D | 78 | 1 | 17 | 18 | 43 | 16 | 5 | 0 | 0 | 0 | 0 | MN: Saginaw | 24 |\\\\n| 88 | Nate Schmidt | D | 63 | 2 | 12 | 14 | 16 | 10 | 3 | 1 | 0 | 1 | 0 | MN: St. Cloud | 32 |\\\\n| 73 | Tyler Toffoli 2 | C | 18 | 7 | 4 | 11 | 2 | 9 | 5 | 2 | 0 | 2 | 0 | ONT: Scarborough | 31 |\\\\n| 19 | David Gustafsson | C | 39 | 3 | 4 | 7 | 0 | 1 | 4 | 1 | 0 | 1 | 2 | Sweden: Tingsryd | 23 |\\\\n| 71 | Axel Jonsson-Fjallby | L | 26 | 2 | 3 | 5 | 0 | 6 | 1 | 0 | 0 | 0 | 0 | Sweden: Stockholm | 25 | [...] | 21 | Dominic Toninato | C | 15 | 1 | 4 | 5 | 6 | 7 | -- | -- | -- | -- | -- | MN: Duluth | 29 |\\\\n| 64 | Logan Stanley | D | 25 | 1 | 1 | 2 | 36 | 4 | 3 | 0 | 1 | 1 | 6 | ONT: Waterloo | 25 |\\\\n|  | Nikita Chibrikov | R | 1 | 1 | 0 | 1 | 0 | 0 | -- | -- | -- | -- | -- | Russia: Moscow | 20 |\\\\n|  | Brad Lambert | C | 1 | 0 | 1 | 1 | 0 | 1 | -- | -- | -- | -- | -- | Finland: Lahti | 19 |\\\\n| 47 | Declan Chisholm 3 | D | 2 | 0 | 1 | 1 | 0 | 1 | -- | -- | -- | -- | -- | ONT: Bowmanville | 23 |\", \"score\": 0.80771893}, {\"title\": \"Team Captains of Winnipeg Jets - Elite Prospects\", \"url\": \"https://www.eliteprospects.com/team/9966/winnipeg-jets/captaincy-history\", \"content\": \"| Season | League | ‚ÄúC‚Äù Captain(s) | ‚ÄúA‚Äù Alternate Captain(s) |\\\\n| --- | --- | --- | --- |\\\\n| 2025-2026  2025-26 | NHL | Adam Lowry |  |\\\\n| 2024-2025  2024-25 | NHL | Adam Lowry | Josh Morrissey  Neal Pionk  Mark Scheifele |\\\\n| 2023-2024  2023-24 | NHL | Adam Lowry | Josh Morrissey  Mark Scheifele |\\\\n| 2022-2023  2022-23 | NHL |  | Adam Lowry  Josh Morrissey  Mark Scheifele |\\\\n| 2021-2022  2021-22 | NHL | Blake Wheeler | Josh Morrissey  Mark Scheifele | [...] | Name | League |\\\\n| --- | --- |\\\\n| Canada Andy Andreoff (F) | NL |\\\\n| USA Anthony Greco (F) | NL |\\\\n| Canada Chase Stillman (F) | AHL |\\\\n| Canada Macoy Erkamps (D) | HockeyAllsvenskan |\\\\n| USA Kieffer Bellows (F) | SHL |\\\\n| Denmark Markus Lauridsen (D) | ICEHL |\\\\n| Canada Peter Aubry (G) | Ligue Magnus |\\\\n| Sweden Victor Eklund (F) | SHL |\\\\n| Latvia Arturs Silovs (G) | NHL |\\\\n| Canada Jakin Smallwood (F) | USports |\\\\n| Canada Gavin McKenna (F) | NCAA |\\\\n| Canada Charles Martin (D) | AHL | [...] Canada\\\\nUSA\\\\nCanada\\\\nCanada\\\\nUSA\\\\nDenmark\\\\nCanada\\\\nSweden\\\\nLatvia\\\\nCanada\\\\nCanada\\\\nCanada\\\\nUSA\\\\nSlovakia\\\\nCanada\\\\nCanada\\\\nCanada\\\\nCanada\\\\nSweden\\\\nCanada\\\\n\\\\n##### Scoring Leaders\\\\n\\\\n| # | Player | GP | G | A | TP |\\\\n| --- | --- | --- | --- | --- | --- |\\\\n| 1. | Tanner Hopps | 18 | 20 | 32 | 52 |\\\\n| 2. | Yu Hikosaka | 20 | 26 | 23 | 49 |\\\\n| 3. | Scott Timmins | 18 | 16 | 31 | 47 |\\\\n| 4. | Joakim Erdugan | 21 | 13 | 33 | 46 |\\\\n| 5. | Kolton Shindle | 18 | 25 | 20 | 45 |\\\\n\\\\n##### Popular League Pages\\\\n\\\\n##### NHL Rosters\", \"score\": 0.7803451}, {\"title\": \"2023 Winnipeg Jets Stats & Leaders - NHL Defense Stats | FOX Sports\", \"url\": \"https://www.foxsports.com/nhl/winnipeg-jets-team-stats?category=defense&season=2023&seasonType=reg\", \"content\": \"|  |  |  |  |  |  |  |  |  |  |  |  |\\\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\\\n| 1 | Josh Morrissey D | 81 | 34 | 44 | 0.5 | 45 | 42 | 1.07 | 103 | 90 | 1.1 |\\\\n| 2 | Mark Scheifele C | 74 | 19 | 57 | 0.8 | 45 | 33 | 1.36 | 40 | 63 | 0.9 |\\\\n| 3 | Kyle Connor LW | 65 | -6 | 6 | 0.1 | 39 | 31 | 1.26 | 19 | 14 | 0.2 |\\\\n| 4 | Adam Lowry C | 81 | 17 | 57 | 0.7 | 38 | 17 | 2.24 | 65 | 181 | 2.2 | [...] | 11 | Gabriel Vilardi C | 47 | 11 | 14 | 0.3 | 21 | 13 | 1.62 | 24 | 14 | 0.3 |\\\\n| 12 | Nino Niederreiter RW | 77 | 12 | 34 | 0.4 | 21 | 17 | 1.24 | 42 | 115 | 1.5 |\\\\n| 13 | Sean Monahan C | 34 | 9 | 2 | 0.1 | 19 | 9 | 2.11 | 20 | 12 | 0.3 |\\\\n| 14 | Cole Perfetti C | 71 | 13 | 12 | 0.2 | 18 | 12 | 1.50 | 23 | 26 | 0.4 |\\\\n| 15 | Nate Schmidt D | 63 | 10 | 16 | 0.3 | 17 | 26 | 0.65 | 76 | 66 | 1.0 |\\\\n| 16 | Vladislav Namestnikov C | 78 | 17 | 37 | 0.5 | 16 | 17 | 0.94 | 45 | 92 | 1.2 | [...] | 23 | Logan Stanley D | 25 | 4 | 36 | 1.4 | 5 | 15 | 0.33 | 40 | 45 | 1.8 |\\\\n| 24 | Laurent Brossoit G | 23 | 0 | 2 | 0.1 | 4 | 8 | 0.50 | 0 | 0 | 0.0 |\\\\n| 25 | Axel Jonsson-Fjallby LW | 26 | 6 | 0 | 0.0 | 3 | 3 | 1.00 | 7 | 30 | 1.1 |\\\\n| 26 | Dominic Toninato C | 15 | 7 | 6 | 0.4 | 3 | 4 | 0.75 | 9 | 26 | 1.7 |\\\\n| 27 | Colin Miller D | 5 | -2 | 2 | 0.4 | 1 | 1 | 1.00 | 4 | 12 | 2.4 |\\\\n| 28 | Brad Lambert C | 1 | 1 | 0 | 0.0 | 0 | 0 | - | 1 | 0 | 0.0 |\", \"score\": 0.75464433}]', name='tavily_search_results_json', id='d1ad42f1-8d6a-4ce6-9aa3-609a9a239a33', tool_call_id='call_j2gKRA8irhzWgIj8t6mm8U5I', artifact={'query': 'current captain of the Winnipeg Jets 2023', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://en.wikipedia.org/wiki/Adam_Lowry', 'title': 'Adam Lowry - Wikipedia', 'content': '| Awards and achievements | | |\\n| --- | --- | --- |\\n| Preceded by Stefan Elliott | Winner of the Daryl K. (Doc) Seaman Trophy_Seaman_Trophy \"Daryl K. (Doc) Seaman Trophy\")  2010 | Succeeded by Colin Smith \"Colin Smith (ice hockey)\") |\\n| Sporting positions | | |\\n| Preceded by Blake Wheeler | Winnipeg Jets captain  2023‚Äìpresent | Incumbent | [...] Entering the 2023‚Äì24 season, Lowry was named captain of the Jets on September 12, 2023. He became the third in the team\\'s history since relocating to Winnipeg, and the tenth overall in franchise history.\\n\\nOn May 4, 2025, Lowry scored at 16:10 in double overtime to win 4-3 against the St. Louis Blues in Game 7 of the Jets-Blues first round playoff series.\\n\\n## Personal life [...] Adam Lowry (born March 29, 1993) is an American-born Canadian professional ice hockey centre \"Center (ice hockey)\") and  captain \"Captain (ice hockey)\") of the Winnipeg Jets of the National Hockey League (NHL).\\n\\n## Early life', 'score': 0.8896154, 'raw_content': None}, {'url': 'https://www.nhl.com/jets/news/adam-lowry-named-jets-captain', 'title': 'Adam Lowry named Jets captain | Winnipeg Jets - NHL.com', 'content': 'The 30-year-old wore an √¢\\x80\\x9cA√¢\\x80\\x9d for the first time in 2022-23 along with Josh Morrissey and Mark Scheifele who will both serve as alternates for the team this year. The Jets didn√¢\\x80\\x99t have a captain last season as head coach Rick Bowness and his staff wanted more voices in the dressing room.\\n\\n√¢\\x80\\x9cIt went well last year. Mark, Adam and Josh did a great job in the room which is what we wanted. We all know Adam is the first guy on the ice to stick up for his teammates,√¢\\x80\\x9d said Bowness. [...] √¢\\x80\\x9cHe√¢\\x80\\x99s a true professional, he has total respect from every player on the team, every player around the league and certainly from the coaching staff as well. We just feel at this point it√¢\\x80\\x99s the right time to name Adam as our captain.√¢\\x80\\x9d [...] √¢\\x80\\x9cGetting to be a captain of a Canadian NHL team is pretty special and something I√¢\\x80\\x99m really looking forward too.√¢\\x80\\x9d', 'score': 0.85509074, 'raw_content': None}, {'url': 'https://www.hockeydb.com/ihdb/stats/leagues/seasons/teams/0063782024.html', 'title': 'Winnipeg Jets 2023-24 roster and scoring statistics at hockeydb.com', 'content': '| 2 | Dylan DeMelo | D | 82 | 3 | 28 | 31 | 36 | 46 | 5 | 0 | 1 | 1 | 2 | ONT: London | 30 |\\n| 9 | Alex Iafallo | L | 82 | 11 | 16 | 27 | 6 | 14 | 5 | 0 | 1 | 1 | 0 | NY: Eden | 29 |\\n| 23 | Sean Monahan 1 | C | 34 | 13 | 11 | 24 | 2 | 9 | 5 | 0 | 1 | 1 | 0 | ONT: Brampton | 28 |\\n| 5 | Brenden Dillon | D | 77 | 8 | 12 | 20 | 92 | 20 | 3 | 0 | 3 | 3 | 4 | BC: New Westminster | 32 |\\n| 36 | Morgan Barron | C | 80 | 11 | 7 | 18 | 23 | 10 | -- | -- | -- | -- | -- | NS: Halifax | 24 | [...] | 54 | Dylan Samberg | D | 78 | 1 | 17 | 18 | 43 | 16 | 5 | 0 | 0 | 0 | 0 | MN: Saginaw | 24 |\\n| 88 | Nate Schmidt | D | 63 | 2 | 12 | 14 | 16 | 10 | 3 | 1 | 0 | 1 | 0 | MN: St. Cloud | 32 |\\n| 73 | Tyler Toffoli 2 | C | 18 | 7 | 4 | 11 | 2 | 9 | 5 | 2 | 0 | 2 | 0 | ONT: Scarborough | 31 |\\n| 19 | David Gustafsson | C | 39 | 3 | 4 | 7 | 0 | 1 | 4 | 1 | 0 | 1 | 2 | Sweden: Tingsryd | 23 |\\n| 71 | Axel Jonsson-Fjallby | L | 26 | 2 | 3 | 5 | 0 | 6 | 1 | 0 | 0 | 0 | 0 | Sweden: Stockholm | 25 | [...] | 21 | Dominic Toninato | C | 15 | 1 | 4 | 5 | 6 | 7 | -- | -- | -- | -- | -- | MN: Duluth | 29 |\\n| 64 | Logan Stanley | D | 25 | 1 | 1 | 2 | 36 | 4 | 3 | 0 | 1 | 1 | 6 | ONT: Waterloo | 25 |\\n|  | Nikita Chibrikov | R | 1 | 1 | 0 | 1 | 0 | 0 | -- | -- | -- | -- | -- | Russia: Moscow | 20 |\\n|  | Brad Lambert | C | 1 | 0 | 1 | 1 | 0 | 1 | -- | -- | -- | -- | -- | Finland: Lahti | 19 |\\n| 47 | Declan Chisholm 3 | D | 2 | 0 | 1 | 1 | 0 | 1 | -- | -- | -- | -- | -- | ONT: Bowmanville | 23 |', 'score': 0.80771893, 'raw_content': None}, {'url': 'https://www.eliteprospects.com/team/9966/winnipeg-jets/captaincy-history', 'title': 'Team Captains of Winnipeg Jets - Elite Prospects', 'content': '| Season | League | ‚ÄúC‚Äù Captain(s) | ‚ÄúA‚Äù Alternate Captain(s) |\\n| --- | --- | --- | --- |\\n| 2025-2026  2025-26 | NHL | Adam Lowry |  |\\n| 2024-2025  2024-25 | NHL | Adam Lowry | Josh Morrissey  Neal Pionk  Mark Scheifele |\\n| 2023-2024  2023-24 | NHL | Adam Lowry | Josh Morrissey  Mark Scheifele |\\n| 2022-2023  2022-23 | NHL |  | Adam Lowry  Josh Morrissey  Mark Scheifele |\\n| 2021-2022  2021-22 | NHL | Blake Wheeler | Josh Morrissey  Mark Scheifele | [...] | Name | League |\\n| --- | --- |\\n| Canada Andy Andreoff (F) | NL |\\n| USA Anthony Greco (F) | NL |\\n| Canada Chase Stillman (F) | AHL |\\n| Canada Macoy Erkamps (D) | HockeyAllsvenskan |\\n| USA Kieffer Bellows (F) | SHL |\\n| Denmark Markus Lauridsen (D) | ICEHL |\\n| Canada Peter Aubry (G) | Ligue Magnus |\\n| Sweden Victor Eklund (F) | SHL |\\n| Latvia Arturs Silovs (G) | NHL |\\n| Canada Jakin Smallwood (F) | USports |\\n| Canada Gavin McKenna (F) | NCAA |\\n| Canada Charles Martin (D) | AHL | [...] Canada\\nUSA\\nCanada\\nCanada\\nUSA\\nDenmark\\nCanada\\nSweden\\nLatvia\\nCanada\\nCanada\\nCanada\\nUSA\\nSlovakia\\nCanada\\nCanada\\nCanada\\nCanada\\nSweden\\nCanada\\n\\n##### Scoring Leaders\\n\\n| # | Player | GP | G | A | TP |\\n| --- | --- | --- | --- | --- | --- |\\n| 1. | Tanner Hopps | 18 | 20 | 32 | 52 |\\n| 2. | Yu Hikosaka | 20 | 26 | 23 | 49 |\\n| 3. | Scott Timmins | 18 | 16 | 31 | 47 |\\n| 4. | Joakim Erdugan | 21 | 13 | 33 | 46 |\\n| 5. | Kolton Shindle | 18 | 25 | 20 | 45 |\\n\\n##### Popular League Pages\\n\\n##### NHL Rosters', 'score': 0.7803451, 'raw_content': None}, {'url': 'https://www.foxsports.com/nhl/winnipeg-jets-team-stats?category=defense&season=2023&seasonType=reg', 'title': '2023 Winnipeg Jets Stats & Leaders - NHL Defense Stats | FOX Sports', 'content': '|  |  |  |  |  |  |  |  |  |  |  |  |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 1 | Josh Morrissey D | 81 | 34 | 44 | 0.5 | 45 | 42 | 1.07 | 103 | 90 | 1.1 |\\n| 2 | Mark Scheifele C | 74 | 19 | 57 | 0.8 | 45 | 33 | 1.36 | 40 | 63 | 0.9 |\\n| 3 | Kyle Connor LW | 65 | -6 | 6 | 0.1 | 39 | 31 | 1.26 | 19 | 14 | 0.2 |\\n| 4 | Adam Lowry C | 81 | 17 | 57 | 0.7 | 38 | 17 | 2.24 | 65 | 181 | 2.2 | [...] | 11 | Gabriel Vilardi C | 47 | 11 | 14 | 0.3 | 21 | 13 | 1.62 | 24 | 14 | 0.3 |\\n| 12 | Nino Niederreiter RW | 77 | 12 | 34 | 0.4 | 21 | 17 | 1.24 | 42 | 115 | 1.5 |\\n| 13 | Sean Monahan C | 34 | 9 | 2 | 0.1 | 19 | 9 | 2.11 | 20 | 12 | 0.3 |\\n| 14 | Cole Perfetti C | 71 | 13 | 12 | 0.2 | 18 | 12 | 1.50 | 23 | 26 | 0.4 |\\n| 15 | Nate Schmidt D | 63 | 10 | 16 | 0.3 | 17 | 26 | 0.65 | 76 | 66 | 1.0 |\\n| 16 | Vladislav Namestnikov C | 78 | 17 | 37 | 0.5 | 16 | 17 | 0.94 | 45 | 92 | 1.2 | [...] | 23 | Logan Stanley D | 25 | 4 | 36 | 1.4 | 5 | 15 | 0.33 | 40 | 45 | 1.8 |\\n| 24 | Laurent Brossoit G | 23 | 0 | 2 | 0.1 | 4 | 8 | 0.50 | 0 | 0 | 0.0 |\\n| 25 | Axel Jonsson-Fjallby LW | 26 | 6 | 0 | 0.0 | 3 | 3 | 1.00 | 7 | 30 | 1.1 |\\n| 26 | Dominic Toninato C | 15 | 7 | 6 | 0.4 | 3 | 4 | 0.75 | 9 | 26 | 1.7 |\\n| 27 | Colin Miller D | 5 | -2 | 2 | 0.4 | 1 | 1 | 1.00 | 4 | 12 | 2.4 |\\n| 28 | Brad Lambert C | 1 | 1 | 0 | 0.0 | 0 | 0 | - | 1 | 0 | 0.0 |', 'score': 0.75464433, 'raw_content': None}], 'response_time': 3.88})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='The current captain of the Winnipeg Jets is Adam Lowry. He was named captain on September 12, 2023.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 3172, 'total_tokens': 3198, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BtLkhUdzorNK6Rg9n2PTMN9vwWLAe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--ecfa9c30-b6e9-477c-ab68-45ea99a4783c-0', usage_metadata={'input_tokens': 3172, 'output_tokens': 26, 'total_tokens': 3198, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "inputs = {\"messages\" : [HumanMessage(content=\"Who is the current captain of the Winnipeg Jets?\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_2P4UdXTMMbM7xF4FMyz0KvjM', 'function': {'arguments': '{\"query\":\"current captain of the Winnipeg Jets 2023\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 220, 'total_tokens': 246, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BtLkl0QzHuQ70v6TCbB7T4rxlTqvz', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--463d0e1e-66c9-4f05-b420-3f1fb626ca66-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current captain of the Winnipeg Jets 2023'}, 'id': 'call_2P4UdXTMMbM7xF4FMyz0KvjM', 'type': 'tool_call'}], usage_metadata={'input_tokens': 220, 'output_tokens': 26, 'total_tokens': 246, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='[{\"title\": \"Adam Lowry named Jets captain | Winnipeg Jets - NHL.com\", \"url\": \"https://www.nhl.com/jets/news/adam-lowry-named-jets-captain\", \"content\": \"The 30-year-old wore an √¢\\x80\\x9cA√¢\\x80\\x9d for the first time in 2022-23 along with Josh Morrissey and Mark Scheifele who will both serve as alternates for the team this year. The Jets didn√¢\\x80\\x99t have a captain last season as head coach Rick Bowness and his staff wanted more voices in the dressing room.\\\\n\\\\n√¢\\x80\\x9cIt went well last year. Mark, Adam and Josh did a great job in the room which is what we wanted. We all know Adam is the first guy on the ice to stick up for his teammates,√¢\\x80\\x9d said Bowness. [...] √¢\\x80\\x9cHe√¢\\x80\\x99s a true professional, he has total respect from every player on the team, every player around the league and certainly from the coaching staff as well. We just feel at this point it√¢\\x80\\x99s the right time to name Adam as our captain.√¢\\x80\\x9d [...] √¢\\x80\\x9cGetting to be a captain of a Canadian NHL team is pretty special and something I√¢\\x80\\x99m really looking forward too.√¢\\x80\\x9d\", \"score\": 0.85538095}, {\"title\": \"Team Captains of Winnipeg Jets - Elite Prospects\", \"url\": \"https://www.eliteprospects.com/team/9966/winnipeg-jets/captaincy-history\", \"content\": \"Complete list and history of team captains in Winnipeg Jets. ... 2023-24, NHL ¬∑ Adam Lowry ¬∑ Josh Morrissey ¬∑ Mark Scheifele. 2022-2023 2022-23, NHL.\", \"score\": 0.82560414}, {\"title\": \"Lowry named Jets captain, replaces Wheeler | NHL.com\", \"url\": \"https://www.nhl.com/news/adam-lowry-named-winnipeg-captain\", \"content\": \"Adam Lowry was named captain of the Winnipeg Jets on Tuesday. The 30-year-old forward was selected by the Jets in the third round (No.\", \"score\": 0.7507177}, {\"title\": \"List of NHL captains\", \"url\": \"https://www.nhl.com/news/nhl-list-of-captains-335526652\", \"content\": \"Utah Mammoth -- Clayton Keller  \\\\nVancouver Canucks -- Quinn Hughes  \\\\nVegas Golden Knights -- Mark Stone  \\\\nWashington Capitals -- Alex Ovechkin  \\\\nWinnipeg Jets -- Adam Lowry [...] ### NHL Free Agent Tracker\\\\n\\\\nMorgan Barron Winnipeg Jets avoid arbitration with two-year contract\\\\nMorgan Barron Winnipeg Jets avoid arbitration with two-year contract\\\\n\\\\n### Barron signs 2-year, $3.7 million contract with Jets\\\\n\\\\nNHL players file for salary arbitration 2025\\\\nNHL players file for salary arbitration 2025\\\\n\\\\n### Vilardi, Kakko among 11 players to file for NHL salary arbitration\\\\n\\\\n2025-26 regular season to start with tripleheader\\\\n2025-26 regular season to start with tripleheader [...] Anaheim Ducks -- Radko Gudas  \\\\nBoston Bruins -- Vacant  \\\\nBuffalo Sabres -- Rasmus Dahlin  \\\\nCalgary Flames -- Mikael Backlund  \\\\nCarolina Hurricanes -- Jordan Staal  \\\\nChicago Blackhawks -- Nick Foligno  \\\\nColorado Avalanche -- Gabriel Landeskog  \\\\nColumbus Blue Jackets -- Boone Jenner  \\\\nDallas Stars -- Jamie Benn  \\\\nDetroit Red Wings -- Dylan Larkin  \\\\nEdmonton Oilers -- Connor McDavid  \\\\nFlorida Panthers -- Aleksander Barkov  \\\\nLos Angeles Kings -- Anze Kopitar  \\\\nMinnesota Wild -- Jared Spurgeon\", \"score\": 0.54187006}, {\"title\": \"Hockey Operations - Official Winnipeg Jets Website - NHL.com\", \"url\": \"https://www.nhl.com/jets/team/hockey-operations/\", \"content\": \"Mark Morrison. Head Coach ; Morgan Klimchuk. Assistant Coach ; Drew MacIntyre. Developmental Goaltending Coach ; Kody Degenstien. Video Coach\", \"score\": 0.2944538}]', name='tavily_search_results_json', id='236d5ba1-388a-45f1-9c10-219479462aab', tool_call_id='call_2P4UdXTMMbM7xF4FMyz0KvjM', artifact={'query': 'current captain of the Winnipeg Jets 2023', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.nhl.com/jets/news/adam-lowry-named-jets-captain', 'title': 'Adam Lowry named Jets captain | Winnipeg Jets - NHL.com', 'content': 'The 30-year-old wore an √¢\\x80\\x9cA√¢\\x80\\x9d for the first time in 2022-23 along with Josh Morrissey and Mark Scheifele who will both serve as alternates for the team this year. The Jets didn√¢\\x80\\x99t have a captain last season as head coach Rick Bowness and his staff wanted more voices in the dressing room.\\n\\n√¢\\x80\\x9cIt went well last year. Mark, Adam and Josh did a great job in the room which is what we wanted. We all know Adam is the first guy on the ice to stick up for his teammates,√¢\\x80\\x9d said Bowness. [...] √¢\\x80\\x9cHe√¢\\x80\\x99s a true professional, he has total respect from every player on the team, every player around the league and certainly from the coaching staff as well. We just feel at this point it√¢\\x80\\x99s the right time to name Adam as our captain.√¢\\x80\\x9d [...] √¢\\x80\\x9cGetting to be a captain of a Canadian NHL team is pretty special and something I√¢\\x80\\x99m really looking forward too.√¢\\x80\\x9d', 'score': 0.85538095, 'raw_content': None}, {'url': 'https://www.eliteprospects.com/team/9966/winnipeg-jets/captaincy-history', 'title': 'Team Captains of Winnipeg Jets - Elite Prospects', 'content': 'Complete list and history of team captains in Winnipeg Jets. ... 2023-24, NHL ¬∑ Adam Lowry ¬∑ Josh Morrissey ¬∑ Mark Scheifele. 2022-2023 2022-23, NHL.', 'score': 0.82560414, 'raw_content': None}, {'url': 'https://www.nhl.com/news/adam-lowry-named-winnipeg-captain', 'title': 'Lowry named Jets captain, replaces Wheeler | NHL.com', 'content': 'Adam Lowry was named captain of the Winnipeg Jets on Tuesday. The 30-year-old forward was selected by the Jets in the third round (No.', 'score': 0.7507177, 'raw_content': None}, {'url': 'https://www.nhl.com/news/nhl-list-of-captains-335526652', 'title': 'List of NHL captains', 'content': 'Utah Mammoth -- Clayton Keller  \\nVancouver Canucks -- Quinn Hughes  \\nVegas Golden Knights -- Mark Stone  \\nWashington Capitals -- Alex Ovechkin  \\nWinnipeg Jets -- Adam Lowry [...] ### NHL Free Agent Tracker\\n\\nMorgan Barron Winnipeg Jets avoid arbitration with two-year contract\\nMorgan Barron Winnipeg Jets avoid arbitration with two-year contract\\n\\n### Barron signs 2-year, $3.7 million contract with Jets\\n\\nNHL players file for salary arbitration 2025\\nNHL players file for salary arbitration 2025\\n\\n### Vilardi, Kakko among 11 players to file for NHL salary arbitration\\n\\n2025-26 regular season to start with tripleheader\\n2025-26 regular season to start with tripleheader [...] Anaheim Ducks -- Radko Gudas  \\nBoston Bruins -- Vacant  \\nBuffalo Sabres -- Rasmus Dahlin  \\nCalgary Flames -- Mikael Backlund  \\nCarolina Hurricanes -- Jordan Staal  \\nChicago Blackhawks -- Nick Foligno  \\nColorado Avalanche -- Gabriel Landeskog  \\nColumbus Blue Jackets -- Boone Jenner  \\nDallas Stars -- Jamie Benn  \\nDetroit Red Wings -- Dylan Larkin  \\nEdmonton Oilers -- Connor McDavid  \\nFlorida Panthers -- Aleksander Barkov  \\nLos Angeles Kings -- Anze Kopitar  \\nMinnesota Wild -- Jared Spurgeon', 'score': 0.54187006, 'raw_content': None}, {'url': 'https://www.nhl.com/jets/team/hockey-operations/', 'title': 'Hockey Operations - Official Winnipeg Jets Website - NHL.com', 'content': 'Mark Morrison. Head Coach ; Morgan Klimchuk. Assistant Coach ; Drew MacIntyre. Developmental Goaltending Coach ; Kody Degenstien. Video Coach', 'score': 0.2944538, 'raw_content': None}], 'response_time': 3.69})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='The current captain of the Winnipeg Jets is Adam Lowry.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 1175, 'total_tokens': 1188, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BtLkqMKYjB7J89i2xdQwo33m763SI', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5e9ecae3-6f69-4dc4-bae0-7c277f8c057a-0', usage_metadata={'input_tokens': 1175, 'output_tokens': 13, 'total_tokens': 1188, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "inputs = {\"messages\" : [HumanMessage(content=\"Who is the current captain of the Winnipeg Jets?\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7QVFuAmsh7L"
      },
      "source": [
        "Now we can add our dataset to our LangSmith project using the following code which we saw last Thursday!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "RLfrZrgSsn85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'example_ids': ['d7cb3097-c7dc-45a5-817a-a512bcc4044a',\n",
              "  'da21b970-b7df-48cb-a67c-f1a154659b29',\n",
              "  'c292cc15-5904-485e-89d8-fac2c5e153b3',\n",
              "  '84044a1e-86d0-43ba-bba1-5be1e13483fe',\n",
              "  '532bc46a-5f1e-4879-8a87-73fdf4d3a974',\n",
              "  '149c429f-6f41-43a1-9f1f-c7e15e937ffe',\n",
              "  '30ed665e-9628-4529-919c-189e0b20dc30'],\n",
              " 'count': 7}"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dataset_name = f\"Retrieval Augmented Generation - Evaluation Dataset - {uuid4().hex[0:8]}\"\n",
        "\n",
        "dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"Questions about the QLoRA Paper to Evaluate RAG over the same paper.\"\n",
        ")\n",
        "\n",
        "client.create_examples(\n",
        "    inputs=[{\"question\" : q} for q in questions],\n",
        "    outputs=answers,\n",
        "    dataset_id=dataset.id,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciV73F9Q04w0"
      },
      "source": [
        "#### ‚ùì Question #3:\n",
        "\n",
        "How are the correct answers associated with the questions?\n",
        "\n",
        "> NOTE: Feel free to indicate if this is problematic or not\n",
        "\n",
        "Answer:\n",
        "\n",
        "The correct answers are associated with the questions through positional indexing - meaning the order of elements in both lists determines the correspondence. The first question (index 0) matches the first answer (index 0), the second question (index 1) matches the second answer (index 1), and so forth.\n",
        "\n",
        "```python\n",
        "questions = [\n",
        "    \"What optimizer is used in QLoRA?\",                    # Position 0\n",
        "    \"What data type was created in the QLoRA paper?\",      # Position 1\n",
        "    \"What is a Retrieval Augmented Generation system?\",    # Position 2\n",
        "    # ... etc\n",
        "]\n",
        "\n",
        "answers = [\n",
        "    {\"must_mention\" : [\"paged\", \"optimizer\"]},      # Position 0 ‚Üí matches question 0\n",
        "    {\"must_mention\" : [\"NF4\", \"NormalFloat\"]},      # Position 1 ‚Üí matches question 1  \n",
        "    {\"must_mention\" : [\"ground\", \"context\"]},       # Position 2 ‚Üí matches question 2\n",
        "    # ... etc\n",
        "]\n",
        "```\n",
        "\n",
        "In the above case the first question is mapped to the first answer. Similarly for all pairings in the list.\n",
        "\n",
        "When the dataset is created the list is zipped together based on their positions.\n",
        "\n",
        "The above approach is problematic because of several reasons.\n",
        "1. Fragile Dependencies: Any modification to one list without corresponding changes to the other breaks all associations.\n",
        "2. Silent Failures: Mismatched indices won't throw errors but will create incorrect question-answer pairings.\n",
        "3. Maintenance Overhead: Developers must manually ensure both lists stay synchronized\n",
        "4. Poor Readability: The relationship between questions and answers isn't immediately apparent\n",
        "5. No Validation: No automatic checks to ensure lists have matching lengths or logical pairings\n",
        "\n",
        "The more robust approach would be to use a list of dictionaries or tuples where each question is explicitly paired with its answer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lRTXUrTtP9Y"
      },
      "source": [
        "### Task 2: Adding Evaluators\n",
        "\n",
        "Now we can add a custom evaluator to see if our responses contain the expected information.\n",
        "\n",
        "We'll be using a fairly naive exact-match process to determine if our response contains specific strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "QrAUXMFftlAY"
      },
      "outputs": [],
      "source": [
        "from langsmith.evaluation import EvaluationResult, run_evaluator\n",
        "\n",
        "@run_evaluator\n",
        "def must_mention(run, example) -> EvaluationResult:\n",
        "    prediction = run.outputs.get(\"output\") or \"\"\n",
        "    required = example.outputs.get(\"must_mention\") or []\n",
        "    score = all(phrase in prediction for phrase in required)\n",
        "    return EvaluationResult(key=\"must_mention\", score=score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNtHORUh0jZY"
      },
      "source": [
        "#### ‚ùì Question #4:\n",
        "\n",
        "What are some ways you could improve this metric as-is?\n",
        "\n",
        "> NOTE: Alternatively you can suggest where gaps exist in this method.\n",
        "\n",
        "Answer:\n",
        "\n",
        "There are certain limitations with the current metric:\n",
        "\n",
        "1. Exact Match Only:\n",
        "   It only looks for exact phrases, so it misses correct answers that use synonyms or paraphrasing.\n",
        "2. No Context Check:\n",
        "   It doesn‚Äôt verify if the required words are used meaningfully or just listed.\n",
        "3. All-or-Nothing Scoring:\n",
        "   If even one required phrase is missing, the answer gets no credit.\n",
        "4. Insensitive to Case/Formatting:\n",
        "   It may fail if the answer uses different capitalization or punctuation.\n",
        "\n",
        "There are several ways to improve the current metric.\n",
        "1. Fuzzy or Case-Insensitive Matching:\n",
        "   Allow minor spelling differences and ignore capitalization.\n",
        "2. Synonym/Semantic Matching:\n",
        "   Use NLP tools to recognize similar meanings, not just exact words.\n",
        "3. Partial Credit:\n",
        "   Score based on how many required concepts are present, not just all-or-nothing.\n",
        "4. Contextual Validation:\n",
        "   Check that required phrases are used in a relevant and correct context, not just mentioned.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1RJr349zhv7"
      },
      "source": [
        "Task 3: Evaluating\n",
        "\n",
        "All that is left to do is evaluate our agent's response!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "efcf57067cf743d8b4ce059a61cbe02e",
            "53e33aae3b97490c82aec7bbb0d6ebba",
            "ad84e0e971d3455db2efe7dd0d1f803e",
            "72adef9b70dd48198b7322b6c5b113cf",
            "8a61d045ffd44ac58f3f13eb10044836",
            "041e22a9b5514e36bd4d1dac01d5d398",
            "886d762f2a7c421382efb5502c6d42a1",
            "ab91fd625bbd43afbf8c6398193a88d0",
            "716557ad09874dcb989d75f7c74424cd",
            "77d4c0ebaae045b58efc4f789c9a2360",
            "0d622ccc56264fac8fd7508dbdbe6e29"
          ]
        },
        "id": "p5TeCUUkuGld",
        "outputId": "2f7d62a2-e78d-447a-d07b-f9e4d500fb79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'Search Pipeline - Evaluation - 51d6-92a04942' at:\n",
            "https://smith.langchain.com/o/3c2c7006-57b9-4cbe-911e-6f73b4734883/datasets/13d77f85-be0f-48fb-96d7-9ce6247e0746/compare?selectedSessions=d9b1af3b-b004-42f4-b998-a19b5f9fe8f6\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55a26eefe7ff414e9453f150ee1ff615",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "experiment_results = client.evaluate(\n",
        "    agent_chain_with_formatting,\n",
        "    data=dataset_name,\n",
        "    evaluators=[must_mention],\n",
        "    experiment_prefix=f\"Search Pipeline - Evaluation - {uuid4().hex[0:4]}\",\n",
        "    metadata={\"version\": \"1.0.0\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "eeEqU7s05Byu",
        "outputId": "78395075-a05d-4ebd-c798-ed968b935318"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<ExperimentResults Search Pipeline - Evaluation - e10f-8b5d3d5a>"
            ],
            "text/plain": [
              "<ExperimentResults Search Pipeline - Evaluation - e10f-8b5d3d5a>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "experiment_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhTNe4kWrplB"
      },
      "source": [
        "## Part 2: LangGraph with Helpfulness:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1wKRddbIY_S"
      },
      "source": [
        "### Task 3: Adding Helpfulness Check and \"Loop\" Limits\n",
        "\n",
        "Now that we've done evaluation - let's see if we can add an extra step where we review the content we've generated to confirm if it fully answers the user's query!\n",
        "\n",
        "We're going to make a few key adjustments to account for this:\n",
        "\n",
        "1. We're going to add an artificial limit on how many \"loops\" the agent can go through - this will help us to avoid the potential situation where we never exit the loop.\n",
        "2. We'll add to our existing conditional edge to obtain the behaviour we desire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npTYJ8ayR5B3"
      },
      "source": [
        "First, let's define our state again - we can check the length of the state object, so we don't need additional state for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "-LQ84YhyJG0w"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD7EV0HqSQcb"
      },
      "source": [
        "Now we can set our graph up! This process will be almost entirely the same - with the inclusion of one additional node/conditional edge!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Answer:\n",
        "\n",
        "In this cell, we begin constructing a new LangGraph called graph_with_helpfulness_check using the StateGraph API with the AgentState type. This graph will manage the flow of messages between the agent (LLM) and the tools.\n",
        "\n",
        "We define two main nodes:\n",
        "\n",
        "\"agent\" node:\n",
        "This represents the thinking step of the agent. It uses the call_model function, which invokes the language model to process the user‚Äôs input and decide whether to respond directly or trigger a tool.\n",
        "\n",
        "\"action\" node:\n",
        "This node is responsible for executing any tool calls made by the agent. It uses the tool_node component, which wraps all available tools (Wikipedia, Math evaluator, Arxiv, Tavily) and ensures the correct one is called based on the model‚Äôs output.\n",
        "\n",
        "This structure sets up the core building blocks for a reasoning-and-action loop: the agent can think, decide to use a tool, receive the tool result, and think again ‚Äî enabling more helpful and accurate responses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oajBwLkFVi1N"
      },
      "source": [
        "#### üèóÔ∏è Activity #5:\n",
        "\n",
        "Please write markdown for the following cells to explain what each is doing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11c8529c0>"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check = StateGraph(AgentState)\n",
        "\n",
        "graph_with_helpfulness_check.add_node(\"agent\", call_model)\n",
        "graph_with_helpfulness_check.add_node(\"action\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Answer:\n",
        "In this cell, we define `\"agent\"` as the **entry point** of the graph. This means that whenever the graph execution begins (e.g., when a user query is received), it will start at the `\"agent\"` node.\n",
        "\n",
        "The `\"agent\"` node is responsible for processing the user‚Äôs input using the language model and deciding whether to respond directly or call a tool. By setting it as the entry point, we ensure that every interaction starts with reasoning before any action is taken."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11c8529c0>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.set_entry_point(\"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsXeF6xlaXOZ"
      },
      "source": [
        "##### YOUR MARKDOWN HERE\n",
        "\n",
        "Answer:\n",
        "\n",
        "In the below cell, we define the function tool_call_or_helpful, which acts as a custom routing logic for our LangGraph agent. This function determines what the agent should do next based on the current conversation state.\n",
        "\n",
        "Here's what each part does:\n",
        "\n",
        "Tool Call Detection:\n",
        "If the latest message includes a tool call (tool_calls), the function immediately returns \"action\", routing the graph to the tool execution node.\n",
        "\n",
        "Conversation End Check:\n",
        "If the total number of messages exceeds 10, it returns \"END\" to stop the conversation and prevent infinite loops.\n",
        "\n",
        "Helpfulness Evaluation Logic:\n",
        "If no tool call is present and the message count is acceptable, the function evaluates whether the final agent response is helpful.\n",
        "\n",
        "It constructs a prompt that compares the initial user query and the agent's final response.\n",
        "\n",
        "This prompt is passed to a small LLM (gpt-4.1-mini) using a LangChain pipeline composed of:\n",
        "\n",
        "PromptTemplate\n",
        "\n",
        "ChatOpenAI\n",
        "\n",
        "StrOutputParser\n",
        "\n",
        "Decision Based on Helpfulness:\n",
        "\n",
        "If the model outputs \"Y\", the function routes to \"end\" (i.e., the answer was helpful enough to stop).\n",
        "\n",
        "If the model outputs \"N\", it routes to \"continue\" (i.e., the conversation should continue for refinement).\n",
        "\n",
        "This logic adds an intelligent layer to the agent, allowing it to self-assess its response and decide whether to continue or end the conversation ‚Äî making the agent more adaptive and feedback-driven."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "z_Sq3A9SaV1O"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def tool_call_or_helpful(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  if last_message.tool_calls:\n",
        "    return \"action\"\n",
        "\n",
        "  initial_query = state[\"messages\"][0]\n",
        "  final_response = state[\"messages\"][-1]\n",
        "\n",
        "  if len(state[\"messages\"]) > 10:\n",
        "    return END\n",
        "\n",
        "  prompt_template = \"\"\"\\\n",
        "  Given an initial query and a final response, determine if the final response is extremely helpful or not. Please indicate helpfulness with a 'Y' and unhelpfulness as an 'N'.\n",
        "\n",
        "  Initial Query:\n",
        "  {initial_query}\n",
        "\n",
        "  Final Response:\n",
        "  {final_response}\"\"\"\n",
        "\n",
        "  helpfullness_prompt_template = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "  helpfulness_check_model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "\n",
        "  helpfulness_chain = helpfullness_prompt_template | helpfulness_check_model | StrOutputParser()\n",
        "\n",
        "  helpfulness_response = helpfulness_chain.invoke({\"initial_query\" : initial_query.content, \"final_response\" : final_response.content})\n",
        "\n",
        "  if \"Y\" in helpfulness_response:\n",
        "    return \"end\"\n",
        "  else:\n",
        "    return \"continue\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz1u9Vf4SHxJ"
      },
      "source": [
        "#### üèóÔ∏è Activity #4:\n",
        "\n",
        "Please write what is happening in our `tool_call_or_helpful` function!\n",
        "\n",
        "Answer:\n",
        "\n",
        "The tool_call_or_helpful function is responsible for deciding the next step in the agent‚Äôs workflow based on the current state of the conversation. Here‚Äôs what happens inside the function:\n",
        "Checks for Tool Calls:\n",
        "If the latest message from the agent includes a tool call, the function returns \"action\", which tells the system to execute the requested tool.\n",
        "Checks for Loop Limit:\n",
        "If the total number of messages in the conversation exceeds 10, the function returns \"END\" to stop the process and prevent infinite loops.\n",
        "Evaluates Helpfulness:\n",
        "If there is no tool call and the loop limit hasn‚Äôt been reached, the function uses a language model to evaluate whether the agent‚Äôs latest response is ‚Äúextremely helpful‚Äù for the original user query. It does this by prompting a smaller LLM with both the initial query and the latest response, asking for a ‚ÄúY‚Äù (helpful) or ‚ÄúN‚Äù (not helpful).\n",
        "If the model responds with ‚ÄúY‚Äù, the function returns \"end\" to finish the conversation.\n",
        "If the model responds with ‚ÄúN‚Äù, it returns \"continue\", allowing the agent to try again and improve its answer.\n",
        "In summary:\n",
        "This function determines whether to use a tool, end the conversation, or let the agent continue, based on tool usage, conversation length, and a helpfulness check using another language model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BhnBW2YVsJO"
      },
      "source": [
        "##### YOUR MARKDOWN HERE\n",
        "\n",
        "Answer:\n",
        "\n",
        "This cell adds conditional routing logic to the graph. After the \"agent\" node runs, it uses the tool_call_or_helpful function to decide the next step:\n",
        "\n",
        "If \"continue\" ‚Üí loop back to \"agent\"\n",
        "\n",
        "If \"action\" ‚Üí go to the \"action\" node to run a tool\n",
        "\n",
        "If \"end\" ‚Üí stop the graph execution\n",
        "\n",
        "This makes the agent self-evaluate its response and decide whether to act again, try a tool, or finish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVTKnWMbP_8T",
        "outputId": "7f729b1f-311c-4084-ceaf-0da437900c85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11c8529c0>"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    tool_call_or_helpful,\n",
        "    {\n",
        "        \"continue\" : \"agent\",\n",
        "        \"action\" : \"action\",\n",
        "        \"end\" : END\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGDLEWOIVtK0"
      },
      "source": [
        "##### YOUR MARKDOWN HERE\n",
        "\n",
        "Answer:\n",
        "This cell adds an edge from the \"action\" node back to the \"agent\" node.\n",
        "After a tool is used, the agent receives the tool's output and continues reasoning based on it. This creates a loop where the agent can think ‚Üí act ‚Üí think again, enabling multi-step reasoning with tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbDK2MbuREgU",
        "outputId": "21a64c20-27a1-4e0e-afde-a639abaa8b55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11c8529c0>"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.add_edge(\"action\", \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSI8AOaEVvT-"
      },
      "source": [
        "##### YOUR MARKDOWN HERE\n",
        "\n",
        "Answer:\n",
        "This cell compiles the graph_with_helpfulness_check into an executable agent called agent_with_helpfulness_check.\n",
        "It finalizes the structure of the LangGraph so it can be invoked with user inputs. After compilation, the agent is ready to run with the defined nodes, edges, and conditional logic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "oQldl8ERQ8lf"
      },
      "outputs": [],
      "source": [
        "agent_with_helpfulness_check = graph_with_helpfulness_check.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F67FGCMRVwGz"
      },
      "source": [
        "##### YOUR MARKDOWN HERE\n",
        "\n",
        "Answer:\n",
        "\n",
        "This cell sends a multi-part user query to the agent_with_helpfulness_check and streams its execution step by step.\n",
        "\n",
        "The input includes three related questions about LoRA, Tim Dettmers, and Attention.\n",
        "\n",
        "The astream method allows us to observe each update from the graph in real time.\n",
        "\n",
        "As the agent runs, we see which node is active (\"agent\" or \"action\") and the messages being passed.\n",
        "\n",
        "This helps us understand how the agent thinks, calls tools, and builds its final response across multiple steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3oo8E-PRK1T",
        "outputId": "f152dea8-96ad-4d29-d8b2-a064c96a8bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_cVZoLMfLX3ls6Ac3bvlOxzFM', 'function': {'arguments': '{\"query\": \"LoRA machine learning\"}', 'name': 'wikipedia'}, 'type': 'function'}, {'id': 'call_7rc1AVuQxFrcCFYj2EoFZmqv', 'function': {'arguments': '{\"query\": \"Tim Dettmers\"}', 'name': 'wikipedia'}, 'type': 'function'}, {'id': 'call_6pP4NSFJpudApvW4X03vCD1z', 'function': {'arguments': '{\"query\": \"Attention (machine learning)\"}', 'name': 'wikipedia'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 235, 'total_tokens': 300, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BtLrN5fu4MQx873PNG1mNGuXY1zsu', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b55683db-6112-4b79-8441-71193c7f8162-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'LoRA machine learning'}, 'id': 'call_cVZoLMfLX3ls6Ac3bvlOxzFM', 'type': 'tool_call'}, {'name': 'wikipedia', 'args': {'query': 'Tim Dettmers'}, 'id': 'call_7rc1AVuQxFrcCFYj2EoFZmqv', 'type': 'tool_call'}, {'name': 'wikipedia', 'args': {'query': 'Attention (machine learning)'}, 'id': 'call_6pP4NSFJpudApvW4X03vCD1z', 'type': 'tool_call'}], usage_metadata={'input_tokens': 235, 'output_tokens': 65, 'total_tokens': 300, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mayankshah/Documents/ai-makerspace/aie7-bootcamp/AIE7_local/05_Our_First_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /Users/mayankshah/Documents/ai-makerspace/aie7-bootcamp/AIE7_local/05_Our_First_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='Page: Fine-tuning (deep learning)\\nSummary: In deep learning, fine-tuning is an approach to transfer learning in which the parameters of a pre-trained neural network model are trained on new data. Fine-tuning can be done on the entire neural network, or on only a subset of its layers, in which case the layers that are not being fine-tuned are \"frozen\" (i.e., not changed during backpropagation). A model may also be augmented with \"adapters\" that consist of far fewer parameters than the original model, and fine-tuned in a parameter-efficient way by tuning the weights of the adapters and leaving the rest of the model\\'s weights frozen.\\nFor some architectures, such as convolutional neural networks, it is common to keep the earlier layers (those closest to the input layer) frozen, as they capture lower-level features, while later layers often discern high-level features that can be more related to the task that the model is trained on.\\nModels that are pre-trained on large, general corpora are usually fine-tuned by reusing their parameters as a starting point and adding a task-specific layer trained from scratch. Fine-tuning the full model is also common and often yields better results, but is more computationally expensive.\\nFine-tuning is typically accomplished via supervised learning, but there are also techniques to fine-tune a model using weak supervision. Fine-tuning can be combined with a reinforcement learning from human feedback-based objective to produce language models such as ChatGPT (a fine-tuned version of GPT models) and Sparrow.\\n\\n\\n\\nPage: List of datasets for machine-learning research\\nSummary: These datasets are used in machine learning (ML) research and have been cited in peer-reviewed academic journals. Datasets are an integral part of the field of machine learning. Major advances in this field can result from advances in learning algorithms (such as deep learning), computer hardware, and, less-intuitively, the availability of high-quality training datasets. High-quality labeled training datasets for supervised and semi-supervised machine learning algorithms are usually difficult and expensive to produce because of the large amount of time needed to label the data. Although they do not need to be labeled, high-quality datasets for unsupervised learning can also be difficult and costly to produce.\\nMany organizations, including governments, publish and share their datasets. The datasets are classified, based on the licenses, as Open data and Non-Open data.\\nThe datasets from various governmental-bodies are presented in List of open government data sites. The datasets are ported on open data portals. They are made available for searching, depositing and accessing through interfaces like Open API.  The datasets are made available as various sorted types and subtypes.', name='wikipedia', id='96bf505c-886a-45bf-972e-5285551c1bcd', tool_call_id='call_cVZoLMfLX3ls6Ac3bvlOxzFM'), ToolMessage(content='Page: Data parallelism\\nSummary: Data parallelism is parallelization across multiple processors in parallel computing environments. It focuses on distributing the data across different nodes, which operate on the data in parallel. It can be applied on regular data structures like arrays and matrices by working on each element in parallel. It contrasts to task parallelism as another form of parallelism.\\nA data parallel job on an array of n elements can be divided equally among all the processors. Let us assume we want to sum all the elements of the given array and the time for a single addition operation is Ta time units. In the case of sequential execution, the time taken by the process will be n√óTa time units as it sums up all the elements of an array. On the other hand, if we execute this job as a data parallel job on 4 processors the time taken would reduce to (n/4)√óTa + merging overhead time units. Parallel execution results in a speedup of 4 over sequential execution. The locality of data references plays an important part in evaluating the performance of a data parallel programming model. Locality of data depends on the memory accesses performed by the program as well as the size of the cache.\\n\\nPage: Ari Holtzman\\nSummary: Ari Holtzman is a professor of Computer Science at the University of Chicago and an expert in the area of Natural language processing and Computational linguistics. Previously, Holtzman was a PhD student at the University of Washington where he was advised by Luke Zettlemoyer.\\nIn 2017, he was a member of the winning team for the inaugural Alexa Prize for developing a conversational AI system for the Amazon Alexa device. Holtzman has made multiple contributions in the area of text generation and language models such as the introduction of nucleus sampling in 2019, his work on AI safety and neural fake news detection, and the fine-tuning of quantized large language models.\\n\\nPage: Large language model\\nSummary: A large language model (LLM) is a language model trained with self-supervised machine learning on a vast amount of text, designed for natural language processing tasks, especially language generation.\\nThe largest and most capable LLMs are generative pretrained transformers (GPTs), which are largely used in generative chatbots such as ChatGPT, Gemini or Claude. LLMs can be fine-tuned for specific tasks or guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained in.', name='wikipedia', id='5bbf52c8-37fd-48b8-9a38-d5cb79fde46e', tool_call_id='call_7rc1AVuQxFrcCFYj2EoFZmqv'), ToolMessage(content='Page: Attention (machine learning)\\nSummary: In machine learning, attention is a  method that determines the importance of each component in a sequence relative to the other components in that sequence. In natural language processing, importance is represented by \"soft\" weights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings across a fixed-width sequence that can range from tens to millions of tokens in size.\\nUnlike \"hard\" weights, which are computed during the backwards training pass, \"soft\" weights exist only in the forward pass and therefore change with every step of the input. Earlier designs implemented the attention mechanism in a serial recurrent neural network (RNN) language translation system, but a more recent design, namely the transformer, removed the slower sequential RNN and relied more heavily on the faster parallel attention scheme.\\nInspired by ideas about attention in humans, the attention mechanism was developed to address the weaknesses of using information from the hidden layers of recurrent neural networks. Recurrent neural networks favor more recent information contained in words at the end of a sentence, while information earlier in the sentence tends to be attenuated. Attention allows a token equal access to any part of a sentence directly, rather than only through the previous state.\\n\\n\\n\\nPage: Transformer (deep learning architecture)\\nSummary: In deep learning, transformer is an architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\\n\\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. Transformers were first developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n\\n\\nPage: Machine learning\\nSummary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\\nML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.\\nStatistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning. \\nFrom a theoretical viewpoint, probably approximately correct learning provides a framework for describing machine learning.\\n\\n', name='wikipedia', id='847dda2e-a5eb-4013-9bae-ebf131423d97', tool_call_id='call_6pP4NSFJpudApvW4X03vCD1z')]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_QO3yvgk26Bo97Y1ehWDe5fe6', 'function': {'arguments': '{\"query\":\"Tim Dettmers\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 2132, 'total_tokens': 2153, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BtLrQKxfnzSWgk1i0LCEmYuEMfMoZ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--1523c1ab-522d-48fd-9e5b-465bebda4e4b-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Tim Dettmers'}, 'id': 'call_QO3yvgk26Bo97Y1ehWDe5fe6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2132, 'output_tokens': 21, 'total_tokens': 2153, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='[{\"title\": \"Tim Dettmers - AI2050 - Schmidt Sciences\", \"url\": \"https://ai2050.schmidtsciences.org/fellow/tim-dettmers/\", \"content\": \"Tim Dettmers is an Assistant Professor at Carnegie Mellon University and a Research Scientist at the Allen Institute for AI, and his research focuses on making foundation models, such as ChatGPT, accessible to researchers and practitioners by reducing their resource requirements. This involves developing novel compression and networking algorithms and building systems that allow for memory-efficient, fast, and cheap deep learning. He has won oral, spotlight, and best paper awards at conferences [...] such as ICLR and NeurIPS. He created the bitsandbytes library for efficient deep learning, which is growing at 2.2 million installations per month, and received Google Open Source and PyTorch Foundation awards. [...] AI models like ChatGPT work well for general use but fail in specialized expert domains, such as the medical sciences. To make AI models work in expert domains, one must adapt them, which is costly and requires significant AI expertise. This project overcomes these cost and expertise barriers through two new approaches: (1) use AI models themselves to perform the AI model adaptation process automatically; (2) make the adaptation process cheap so it can be run on regular consumer hardware. With\", \"score\": 0.9245858}, {\"title\": \"Tim Dettmers - OpenReview\", \"url\": \"https://openreview.net/profile?id=~Tim_Dettmers2\", \"content\": \"Toggle navigationOpenReview.net\\\\n\\\\n   Login\\\\n\\\\n√ó\\\\n\\\\n√ó\\\\n### BibTeX Record\\\\n\\\\n_Click anywhere on the box above to highlight complete record_\\\\n\\\\nDone\\\\n\\\\nTim Dettmers\\\\n============\\\\n\\\\n### Assistant Professor, Machine learning; Computer Science, Carnegie Mellon University\\\\n\\\\n### Researcher, Allen Institute for Artificial Intelligence\\\\n\\\\n    Joined September 2019\\\\n\\\\n#### Names\\\\n\\\\nTim Dettmers(Preferred)\\\\n\\\\n   Suggest Name\\\\n\\\\n#### Emails\\\\n\\\\n@gmail.com(Confirmed)\\\\n\\\\n, \\\\n\\\\n@cs.washington.edu(Confirmed)\\\\n\\\\n, \\\\n\\\\n@fb.com(Confirmed)\\\\n\\\\n, [...] @allenai.org(Confirmed)\\\\n\\\\n, \\\\n\\\\n@cmu.edu(Confirmed)\\\\n\\\\n   Suggest Email\\\\n\\\\n#### Personal Links\\\\n\\\\nHomepage\\\\n\\\\nGoogle Scholar\\\\n\\\\nDBLP\\\\n\\\\n   Suggest URL\\\\n\\\\n#### Career & Education History\\\\n\\\\nAssistant Professor\\\\n\\\\nMachine learning; Computer Science, Carnegie Mellon University(cmu.edu)\\\\n\\\\n_2025 ‚Äì Present_\\\\n\\\\nResearcher\\\\n\\\\nAllen Institute for Artificial Intelligence(allenai.org)\\\\n\\\\n_2024 ‚Äì Present_\\\\n\\\\nPhD student\\\\n\\\\nComputer Science, University of Washington(cs.washington.edu)\\\\n\\\\n_2018 ‚Äì 2024_\\\\n\\\\n   Suggest Position\", \"score\": 0.70531887}, {\"title\": \"About Me - Tim Dettmers\", \"url\": \"https://timdettmers.com/about/\", \"content\": \"Research Interests  \\\\nPublications  \\\\nAwards & Honors  \\\\nService\\\\n\\\\nGoogle Scholar\\\\n\\\\nfirstname.lastname@gmail.com\\\\n\\\\nImage 1I am a research scientist at the Allen Institute for Artificial Intelligence (Ai2) and an incoming Assistant Professor at Carnegie Mellon University (CMU). I am the creator and maintainer of bitsandbytes. [...] I have a PhD from University of Washington advised by Luke Zettlemoyer working on efficient deep learning at the intersection between machine learning, natural language processing, and computer systems with a focus on quantization and sparsity. My main research goal is to empower everyone to make AI their own. I do this by making large models accessible through my research (QLoRA, LLM.int8(), k-bit inference scaling laws, Petals, SWARM) and by developing software that makes it easy to use my [...] About Me ‚Äî Tim Dettmers\\\\n===============  \\\\n\\\\nSkip links\\\\n----------\\\\n\\\\n   Skip to primary navigation\\\\n   Skip to content\\\\n   Skip to primary sidebar\\\\n\\\\nTim Dettmers\\\\n\\\\nMaking deep learning accessible.\\\\n\\\\nHeader Right\\\\n------------\\\\n\\\\n### Blog Posts Topics\\\\n\\\\n   Academia (4)\\\\n       PhD Life (3)\\\\n   Deep Learning (7)\\\\n   Hardware (8)\\\\n   Science (4)\\\\n       Neuroscience (1)\\\\n\\\\nMain navigation\\\\n---------------\\\\n\\\\n   Blog\\\\n       Deep Learning\\\\n       Hardware\\\\n       Neuroscience\\\\n   Publications\\\\n   About Me\\\\n\\\\nAbout Me\\\\n========\", \"score\": 0.68318754}, {\"title\": \"Tim Dettmers | Carnegie Mellon University Computer Science ...\", \"url\": \"https://csd.cmu.edu/people/faculty/tim-dettmers\", \"content\": \"X\\\\n\\\\nBreadcrumb\\\\n----------\\\\n\\\\n1.  Home\\\\n2.  People\\\\n3.  Faculty\\\\n4.  Tim Dettmers\\\\n\\\\nTim Dettmers\\\\n============\\\\n\\\\nImage 2: Tim DettmersAssistant Professor\\\\n\\\\nWebsite\\\\n\\\\nGoogle Scholars Link\\\\n\\\\nEmail dettmers@cmu.edu\\\\n\\\\nDepartment  \\\\nMachine Learning Department  \\\\nComputer Science Department\\\\n\\\\nComputer Science Department\\\\n---------------------------\\\\n\\\\nCarnegie Mellon University\\\\n\\\\n5000 Forbes Avenue\\\\n\\\\nPittsburgh, PA 15213\\\\n\\\\nFax: 412-268-5576\\\\n\\\\n            \\\\n\\\\nImage 3: Carnegie Mellon University School of Computer Science [...] About\\\\n    \\\\n    ### Back to Main Menu\\\\n    \\\\n    ### About Main page\\\\n    \\\\n       About  \\\\n        Related links\\\\n           Events\\\\n           News\\\\n           Key Contacts\\\\n           History\\\\n           Sitemap\\\\n       Employment  \\\\n        Related links\\\\n           Faculty Hiring\\\\n           Staff Hiring\\\\n       Marketing & Communications  \\\\n        Related links\\\\n           SCS Marketing & Communications\\\\n           Partnerships\\\\n           Employer Recruiting\\\\n           CMU Marketing & Communications\", \"score\": 0.6729558}, {\"title\": \"Tim Dettmers - Quora\", \"url\": \"https://www.quora.com/profile/Tim-Dettmers-1\", \"content\": \"Kernel methods are practically obsolete, but their math still shines on and is worth a look. Kernel methods are not only practically obsolete due to their inferior predictive performance when compared to deep learning, but also because they require a lot of feature engineering and because they are se‚Ä¶\\\\n\\\\n(more)\\\\n\\\\nImage 8: Profile photo for Tim Dettmers\\\\n\\\\nTim Dettmers\\\\n\\\\nPhD Student at University of Washington (2018‚Äìpresent)\\\\n\\\\n¬∑9y [...] PhD Student at University of Washington (2018‚Äìpresent)\\\\n\\\\n¬∑9y\\\\n\\\\nHow feasible would it be to build a deep learning platform on a distributed heterogeneous environment over the Internet (e.g. desktop/mobile grid)? [...] Image 9: Profile photo for Tim Dettmers\\\\n\\\\nTim Dettmers\\\\n\\\\nPhD Student at University of Washington (2018‚Äìpresent)\\\\n\\\\n¬∑9y\\\\n\\\\nHow can I use a deep neural network trained model by multiple GPUs?\\\\n\\\\nIf you want to use multiple GPUs you should use Torch7 along with the Facebook research libraries. The parallel implementations of Torch7 provide good speed, without any loss of accuracy and are very easy to use. There are other libraries that make use of parallelism, but they often have poor APIs o‚Ä¶\\\\n\\\\n(more)\", \"score\": 0.57666177}]', name='tavily_search_results_json', id='5376758d-640d-40cc-9453-c9ecee2f07b7', tool_call_id='call_QO3yvgk26Bo97Y1ehWDe5fe6', artifact={'query': 'Tim Dettmers', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://ai2050.schmidtsciences.org/fellow/tim-dettmers/', 'title': 'Tim Dettmers - AI2050 - Schmidt Sciences', 'content': 'Tim Dettmers is an Assistant Professor at Carnegie Mellon University and a Research Scientist at the Allen Institute for AI, and his research focuses on making foundation models, such as ChatGPT, accessible to researchers and practitioners by reducing their resource requirements. This involves developing novel compression and networking algorithms and building systems that allow for memory-efficient, fast, and cheap deep learning. He has won oral, spotlight, and best paper awards at conferences [...] such as ICLR and NeurIPS. He created the bitsandbytes library for efficient deep learning, which is growing at 2.2 million installations per month, and received Google Open Source and PyTorch Foundation awards. [...] AI models like ChatGPT work well for general use but fail in specialized expert domains, such as the medical sciences. To make AI models work in expert domains, one must adapt them, which is costly and requires significant AI expertise. This project overcomes these cost and expertise barriers through two new approaches: (1) use AI models themselves to perform the AI model adaptation process automatically; (2) make the adaptation process cheap so it can be run on regular consumer hardware. With', 'score': 0.9245858, 'raw_content': None}, {'url': 'https://openreview.net/profile?id=~Tim_Dettmers2', 'title': 'Tim Dettmers - OpenReview', 'content': 'Toggle navigationOpenReview.net\\n\\n   Login\\n\\n√ó\\n\\n√ó\\n### BibTeX Record\\n\\n_Click anywhere on the box above to highlight complete record_\\n\\nDone\\n\\nTim Dettmers\\n============\\n\\n### Assistant Professor, Machine learning; Computer Science, Carnegie Mellon University\\n\\n### Researcher, Allen Institute for Artificial Intelligence\\n\\n    Joined September 2019\\n\\n#### Names\\n\\nTim Dettmers(Preferred)\\n\\n   Suggest Name\\n\\n#### Emails\\n\\n@gmail.com(Confirmed)\\n\\n, \\n\\n@cs.washington.edu(Confirmed)\\n\\n, \\n\\n@fb.com(Confirmed)\\n\\n, [...] @allenai.org(Confirmed)\\n\\n, \\n\\n@cmu.edu(Confirmed)\\n\\n   Suggest Email\\n\\n#### Personal Links\\n\\nHomepage\\n\\nGoogle Scholar\\n\\nDBLP\\n\\n   Suggest URL\\n\\n#### Career & Education History\\n\\nAssistant Professor\\n\\nMachine learning; Computer Science, Carnegie Mellon University(cmu.edu)\\n\\n_2025 ‚Äì Present_\\n\\nResearcher\\n\\nAllen Institute for Artificial Intelligence(allenai.org)\\n\\n_2024 ‚Äì Present_\\n\\nPhD student\\n\\nComputer Science, University of Washington(cs.washington.edu)\\n\\n_2018 ‚Äì 2024_\\n\\n   Suggest Position', 'score': 0.70531887, 'raw_content': None}, {'url': 'https://timdettmers.com/about/', 'title': 'About Me - Tim Dettmers', 'content': 'Research Interests  \\nPublications  \\nAwards & Honors  \\nService\\n\\nGoogle Scholar\\n\\nfirstname.lastname@gmail.com\\n\\nImage 1I am a research scientist at the Allen Institute for Artificial Intelligence (Ai2) and an incoming Assistant Professor at Carnegie Mellon University (CMU). I am the creator and maintainer of bitsandbytes. [...] I have a PhD from University of Washington advised by Luke Zettlemoyer working on efficient deep learning at the intersection between machine learning, natural language processing, and computer systems with a focus on quantization and sparsity. My main research goal is to empower everyone to make AI their own. I do this by making large models accessible through my research (QLoRA, LLM.int8(), k-bit inference scaling laws, Petals, SWARM) and by developing software that makes it easy to use my [...] About Me ‚Äî Tim Dettmers\\n===============  \\n\\nSkip links\\n----------\\n\\n   Skip to primary navigation\\n   Skip to content\\n   Skip to primary sidebar\\n\\nTim Dettmers\\n\\nMaking deep learning accessible.\\n\\nHeader Right\\n------------\\n\\n### Blog Posts Topics\\n\\n   Academia (4)\\n       PhD Life (3)\\n   Deep Learning (7)\\n   Hardware (8)\\n   Science (4)\\n       Neuroscience (1)\\n\\nMain navigation\\n---------------\\n\\n   Blog\\n       Deep Learning\\n       Hardware\\n       Neuroscience\\n   Publications\\n   About Me\\n\\nAbout Me\\n========', 'score': 0.68318754, 'raw_content': None}, {'url': 'https://csd.cmu.edu/people/faculty/tim-dettmers', 'title': 'Tim Dettmers | Carnegie Mellon University Computer Science ...', 'content': 'X\\n\\nBreadcrumb\\n----------\\n\\n1.  Home\\n2.  People\\n3.  Faculty\\n4.  Tim Dettmers\\n\\nTim Dettmers\\n============\\n\\nImage 2: Tim DettmersAssistant Professor\\n\\nWebsite\\n\\nGoogle Scholars Link\\n\\nEmail dettmers@cmu.edu\\n\\nDepartment  \\nMachine Learning Department  \\nComputer Science Department\\n\\nComputer Science Department\\n---------------------------\\n\\nCarnegie Mellon University\\n\\n5000 Forbes Avenue\\n\\nPittsburgh, PA 15213\\n\\nFax: 412-268-5576\\n\\n            \\n\\nImage 3: Carnegie Mellon University School of Computer Science [...] About\\n    \\n    ### Back to Main Menu\\n    \\n    ### About Main page\\n    \\n       About  \\n        Related links\\n           Events\\n           News\\n           Key Contacts\\n           History\\n           Sitemap\\n       Employment  \\n        Related links\\n           Faculty Hiring\\n           Staff Hiring\\n       Marketing & Communications  \\n        Related links\\n           SCS Marketing & Communications\\n           Partnerships\\n           Employer Recruiting\\n           CMU Marketing & Communications', 'score': 0.6729558, 'raw_content': None}, {'url': 'https://www.quora.com/profile/Tim-Dettmers-1', 'title': 'Tim Dettmers - Quora', 'content': 'Kernel methods are practically obsolete, but their math still shines on and is worth a look. Kernel methods are not only practically obsolete due to their inferior predictive performance when compared to deep learning, but also because they require a lot of feature engineering and because they are se‚Ä¶\\n\\n(more)\\n\\nImage 8: Profile photo for Tim Dettmers\\n\\nTim Dettmers\\n\\nPhD Student at University of Washington (2018‚Äìpresent)\\n\\n¬∑9y [...] PhD Student at University of Washington (2018‚Äìpresent)\\n\\n¬∑9y\\n\\nHow feasible would it be to build a deep learning platform on a distributed heterogeneous environment over the Internet (e.g. desktop/mobile grid)? [...] Image 9: Profile photo for Tim Dettmers\\n\\nTim Dettmers\\n\\nPhD Student at University of Washington (2018‚Äìpresent)\\n\\n¬∑9y\\n\\nHow can I use a deep neural network trained model by multiple GPUs?\\n\\nIf you want to use multiple GPUs you should use Torch7 along with the Facebook research libraries. The parallel implementations of Torch7 provide good speed, without any loss of accuracy and are very easy to use. There are other libraries that make use of parallelism, but they often have poor APIs o‚Ä¶\\n\\n(more)', 'score': 0.57666177, 'raw_content': None}], 'response_time': 2.25})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='### LoRA in Machine Learning\\nLoRA, or Low-Rank Adaptation, is a technique used in the fine-tuning of deep learning models. It involves augmenting a pre-trained model with \"adapters\" that have far fewer parameters than the original model. These adapters are fine-tuned while the rest of the model\\'s parameters remain frozen, allowing for parameter-efficient training. This approach is particularly useful for adapting large models to new tasks without the need for extensive computational resources.\\n\\n### Tim Dettmers\\nTim Dettmers is an Assistant Professor at Carnegie Mellon University and a Research Scientist at the Allen Institute for AI. His research focuses on making large AI models, like ChatGPT, more accessible by reducing their resource requirements. He develops novel compression and networking algorithms to enable memory-efficient, fast, and cost-effective deep learning. Dettmers is known for creating the bitsandbytes library for efficient deep learning and has received several awards for his contributions to the field.\\n\\n### Attention in Machine Learning\\nAttention is a mechanism in machine learning that determines the importance of each component in a sequence relative to others. In natural language processing, it assigns \"soft\" weights to words in a sentence, allowing models to focus on relevant parts of the input. This mechanism was initially implemented in recurrent neural networks (RNNs) but has been more effectively utilized in transformers, which rely on parallel attention schemes. Attention allows models to access any part of a sequence directly, improving the handling of long-range dependencies in data.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 303, 'prompt_tokens': 3739, 'total_tokens': 4042, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2048}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BtLrT4DPm0vccJxpkURacT63saU8e', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3ef0c691-3889-406a-9cfd-0cfa66c3343e-0', usage_metadata={'input_tokens': 3739, 'output_tokens': 303, 'total_tokens': 4042, 'input_token_details': {'audio': 0, 'cache_read': 2048}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"Related to machine learning, what is LoRA? Also, who is Tim Dettmers? Also, what is Attention?\")]}\n",
        "\n",
        "async for chunk in agent_with_helpfulness_check.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVmZPs6lnpsM"
      },
      "source": [
        "### Task 4: LangGraph for the \"Patterns\" of GenAI\n",
        "\n",
        "Let's ask our system about the 4 patterns of Generative AI:\n",
        "\n",
        "1. Prompt Engineering\n",
        "2. RAG\n",
        "3. Fine-tuning\n",
        "4. Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "ZoLl7GlXoae-"
      },
      "outputs": [],
      "source": [
        "patterns = [\"prompt engineering\", \"RAG\", \"fine-tuning\", \"LLM-based agents\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zkh0YJuCp3Zl",
        "outputId": "d847426e-71b3-47e6-b1ae-351a78d68d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Prompt Engineering** is the process of crafting instructions to produce the best possible output from a generative AI model. It involves structuring natural language text to describe the task an AI should perform, which can include queries, commands, or longer statements with context and instructions. This technique is used across various AI models, including text-to-text, text-to-image, and text-to-audio models, to guide the AI in generating desired outputs.\n",
            "\n",
            "**History and Emergence:**\n",
            "Prompt engineering has been around since the early days of natural language processing (NLP). It gained significant attention with the release of OpenAI's GPT-3 in 2020, which showcased the potential of large-scale pretrained models. This marked a watershed moment for prompt engineering, as researchers and developers began exploring how to craft effective prompts to control and guide the model's behavior. The introduction of attention mechanisms in 2015 and subsequent advancements in AI models further enhanced the field, making prompt engineering a critical component in deploying AI systems for various applications.\n",
            "\n",
            "\n",
            "\n",
            "Retrieval-Augmented Generation (RAG) is a technique that enhances large language models (LLMs) by allowing them to retrieve and incorporate new information from specified documents before generating responses. This approach helps LLMs access domain-specific or updated information that isn't available in their pre-existing training data, thereby improving accuracy and reducing AI hallucinations. RAG also reduces the need to retrain LLMs with new data, saving on computational and financial costs, and allows for greater transparency by including sources in responses.\n",
            "\n",
            "The term \"RAG\" was first introduced in a 2020 research paper by Meta. This technique blends the LLM process with a web search or document look-up process to help LLMs stick to factual information.\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mayankshah/Documents/ai-makerspace/aie7-bootcamp/AIE7_local/05_Our_First_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /Users/mayankshah/Documents/ai-makerspace/aie7-bootcamp/AIE7_local/05_Our_First_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuning in machine learning, particularly in deep learning, is a technique used in transfer learning. It involves taking a pre-trained neural network model and further training it on new data to adapt it to a specific task. This can be done on the entire network or just a subset of its layers, with the rest being \"frozen\" (i.e., not updated during training). Fine-tuning is often used to improve the performance of models on specific tasks by leveraging the knowledge already captured in the pre-trained model. This approach is commonly used in models like convolutional neural networks for image classification and transformers for natural language processing tasks.\n",
            "\n",
            "The concept of fine-tuning has been around since the early days of deep learning, but it gained significant traction with the introduction of pre-trained models like AlexNet and VGG. These models demonstrated the effectiveness of using pre-trained architectures as a starting point for specific tasks, leading to widespread adoption of fine-tuning techniques. The evolution of fine-tuning has been driven by advances in deep learning architectures, pre-training methods, and optimization algorithms. Notable milestones include the use of convolutional neural networks for image classification and pre-trained language models like BERT and RoBERTa for text classification and sentiment analysis.\n",
            "\n",
            "\n",
            "\n",
            "LLM-based agents are advanced AI systems that utilize large language models (LLMs) like GPT-4 to perform specialized tasks. These agents are designed to reason through language, use tools, and operate autonomously, often without needing constant human oversight. They can perceive their environment, plan actions, and execute tasks, making them capable of more than just passive response generation. LLM-based agents can recall conversation history, understand user preferences, and adapt their responses, allowing for more natural, human-like interactions.\n",
            "\n",
            "The concept of LLM-based agents represents a shift from passive systems to goal-driven, autonomous entities. They are equipped with long-term memory, multi-step planning, and real-time interaction capabilities. This evolution allows them to perform tasks such as running API calls, booking meetings, browsing the web, and more.\n",
            "\n",
            "The history of LLMs dates back to the 1950s and 60s, with the introduction of early chatbots like Eliza. However, LLMs became more prominent with the introduction of models like ChatGPT. The development of LLM-based agents is a more recent phenomenon, with significant advancements occurring in the 2020s. These agents are expected to continue evolving, with future developments likely to include advancements in multimodality and real-world applications such as AI tutors, healthcare agents, and code generation agents.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for pattern in patterns:\n",
        "  what_is_string = f\"What is {pattern} and when did it break onto the scene??\"\n",
        "  inputs = {\"messages\" : [HumanMessage(content=what_is_string)]}\n",
        "  messages = agent_with_helpfulness_check.invoke(inputs)\n",
        "  print(messages[\"messages\"][-1].content)\n",
        "  print(\"\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
