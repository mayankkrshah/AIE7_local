{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c07708f",
   "metadata": {},
   "source": [
    "Now that you've deployed your endpoint - it's time to slam it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb76763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"TOGETHER_API_KEY\"] = getpass.getpass(\"Enter your Together API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd1778",
   "metadata": {},
   "source": [
    "Let's try with 1 request, just to verify our endpoint is alive.\n",
    "\n",
    "Make sure you provide your own endpoint identifier! It will look something like this:\n",
    "\n",
    "- `your-username-here/openai/gpt-oss-20b-unique-identifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b73147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Short answer:**  \n",
      "A wood‑chuck would chuck *as much wood as a wood‑chuck would if a wood‑chuck could chuck wood* – roughly 700 pounds (≈30 cubic feet) of wood, according to a 1988 tongue‑in‑cheek study by wildlife biologist Richard Thomas.  \n",
      "\n",
      "**Why “700 pounds?”**  \n",
      "Thomas reasoned that a woodchuck (groundhog) moves about 700 lb of dirt while digging its burrow each year. If it was as ambitious with wood, it would probably move a comparable amount.  \n",
      "\n",
      "**So…**  \n",
      "- If you’re singing the classic tongue‑twister, the punchline is a play on words:  \n",
      "  _“A woodchuck would chuck as much wood as a woodchuck would if a woodchuck could chuck wood.”_\n",
      "\n",
      "- If you want a “real” number: about **700 lb (around 32 kg) of wood** seems a fun, memory‑clipboard answer.  \n",
      "\n",
      "Enjoy the chuck‑ducky fun!\n"
     ]
    }
   ],
   "source": [
    "from together import Together\n",
    "\n",
    "client = Together()\n",
    "\n",
    "# REPLACE WITH YOUR OWN ENDPOINT IDENTIFIER\n",
    "model_endpoint = \"openai/gpt-oss-20b\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model_endpoint,\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How much wood could a wood chuck chuck if a wood chuck could chuck wood?\"\n",
    "      }\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea32b5",
   "metadata": {},
   "source": [
    "Now, let's SLAM IT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbce1853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 5: ```json\n",
      "{\"t\":\"Request\",\"i\":5,\"p\":\"How much wood could a wood...\n",
      "Response 11: A woodchuck would chuck *as much wood as a woodchuck could c...\n",
      "Response 15: A classic tongue‑twister with no single “official” answer!  ...\n",
      "Response 4: Sure thing....\n",
      "Request 14 failed: Error code: 500 - {\"message\": \"Internal server error\", \"type_\": \"server_error\"}\n",
      "Response 8: Well, if you take a wood‑chuck that’s got the work ethic of ...\n",
      "Response 7: You’ll hear the same joke answer as always:\n",
      "\n",
      "> **“A wood‑chu...\n",
      "Response 19: Classic tongue‑twister and whimsical question!  \n",
      "In a litera...\n",
      "Response 17: Ah, the classic tongue‑twister!  In the spirit of the joke, ...\n",
      "Response 16: It’s a tongue‑twister, not a real question about wood chucks...\n",
      "Response 2: The classic tongue‑twister doesn’t actually have a scientifi...\n",
      "Response 23: The famous question is really a tongue‑twister and a fun bit...\n",
      "Response 6: **Answer (Request 6)**  \n",
      "\n",
      "The “wood‑chuck” riddle isn’t base...\n",
      "Response 9: Ah, the classic tongue‑twister!  While it’s a playful riddle...\n",
      "Response 20: Here are 20 playful, quick‑fire answers to the classic tongu...\n",
      "Response 10: | URL | Description | Document | Accuracy | Readability | De...\n",
      "Response 24: A woodchuck that *could* chuck wood would be a pretty indust...\n",
      "Response 12: Hah! The classic tongue‑twister answer is the “catch‑all” jo...\n",
      "Response 18: The classic tongue‑twister doesn’t actually have a single “c...\n",
      "Response 13: **Short answer:**  \n",
      "There's no real “scientific” answer – it...\n",
      "Response 1: That classic tongue‑twister doesn’t actually have a single “...\n",
      "Response 21: Ah, the age‑old riddle that tickles tongues and tickles the ...\n",
      "Response 22: That line is one of the classic English tongue‑twisters, and...\n",
      "Response 3: **The classic answer (and a nod to folklore)**  \n",
      "> “A wood‑c...\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from together import AsyncTogether\n",
    "\n",
    "async def send_request(client, idx):\n",
    "    try:\n",
    "        response = await client.chat.completions.create(\n",
    "            model=model_endpoint,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"How much wood could a wood chuck chuck if a wood chuck could chuck wood? (Request {idx})\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        print(f\"Response {idx}: {response.choices[0].message.content[:60]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Request {idx} failed: {e}\")\n",
    "\n",
    "async def main():\n",
    "    client = AsyncTogether()\n",
    "    tasks = [send_request(client, i,) for i in range(1, 25)]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# Run the async main function\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
